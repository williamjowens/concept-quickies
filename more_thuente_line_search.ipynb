{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fnPYT0ZriHKO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Optional, Any, Dict\n",
        "\n",
        "# Define termination messages globally\n",
        "termination_messages = {\n",
        "    0: \"No convergence.\",\n",
        "    1: \"The sufficient decrease condition and the directional derivative condition hold.\",\n",
        "    2: \"Relative width of the interval of uncertainty is at most xtol.\",\n",
        "    3: \"Number of calls to phi has reached maxfev.\",\n",
        "    4: \"The step is at the lower bound alpha_min.\",\n",
        "    5: \"The step is at the upper bound alpha_max.\",\n",
        "    6: \"Rounding errors prevent further progress.\",\n",
        "    7: \"Unable to create finite alpha.\"\n",
        "}\n",
        "\n",
        "def get_termination_message(info_code: int) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves the termination message based on the info code.\n",
        "\n",
        "    Args:\n",
        "        info_code (int): The termination code.\n",
        "\n",
        "    Returns:\n",
        "        str: The corresponding termination message.\n",
        "    \"\"\"\n",
        "    return termination_messages.get(info_code, \"Unknown termination reason.\")\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    \"\"\"\n",
        "    Represents a step in the line search.\n",
        "\n",
        "    Attributes:\n",
        "        alpha (float): Step size.\n",
        "        f (float): Function value at the step.\n",
        "        d (float): Directional derivative at the step.\n",
        "    \"\"\"\n",
        "    alpha: float\n",
        "    f: float\n",
        "    d: float\n",
        "\n",
        "\n",
        "def armijo_ok_step(step0: Step, step: Step, c1: float) -> bool:\n",
        "    \"\"\"\n",
        "    Checks the Armijo (sufficient decrease) condition.\n",
        "\n",
        "    Args:\n",
        "        step0 (Step): Initial step before the line search.\n",
        "        step (Step): Current step being evaluated.\n",
        "        c1 (float): Armijo condition constant.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the condition is satisfied, False otherwise.\n",
        "    \"\"\"\n",
        "    return step.f <= step0.f + c1 * step0.d * step.alpha\n",
        "\n",
        "\n",
        "def make_approx_armijo_ok_step(eps: float) -> Callable[[Step, Step, float], bool]:\n",
        "    \"\"\"\n",
        "    Creates an approximate Armijo condition checker with tolerance.\n",
        "\n",
        "    Args:\n",
        "        eps (float): Tolerance for the approximation.\n",
        "\n",
        "    Returns:\n",
        "        Callable[[Step, Step, float], bool]: A function that checks the approximate Armijo condition.\n",
        "    \"\"\"\n",
        "    def approx_armijo_ok_step(step0: Step, step: Step, c1: float) -> bool:\n",
        "        return step.f <= step0.f + c1 * step0.d * step.alpha + eps\n",
        "    return approx_armijo_ok_step\n",
        "\n",
        "\n",
        "def curvature_ok_step(step0: Step, step: Step, c: float) -> bool:\n",
        "    \"\"\"\n",
        "    Checks the curvature condition.\n",
        "\n",
        "    Args:\n",
        "        step0 (Step): Initial step before the line search.\n",
        "        step (Step): Current step being evaluated.\n",
        "        c (float): Curvature condition constant.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the condition is satisfied, False otherwise.\n",
        "    \"\"\"\n",
        "    return abs(step.d) <= c * abs(step0.d)\n",
        "\n",
        "\n",
        "def make_wolfe_ok_step_fn(strong_curvature: bool = True,\n",
        "                          approx_armijo: bool = False,\n",
        "                          eps: float = 1e-6) -> Callable[[Step, Step, float, float], bool]:\n",
        "    \"\"\"\n",
        "    Creates a function to check Wolfe conditions.\n",
        "\n",
        "    Args:\n",
        "        strong_curvature (bool): If True, checks the strong Wolfe condition.\n",
        "        approx_armijo (bool): If True, uses an approximate Armijo condition.\n",
        "        eps (float): Tolerance for the approximate Armijo condition.\n",
        "\n",
        "    Returns:\n",
        "        Callable[[Step, Step, float, float], bool]: A function that checks the Wolfe conditions.\n",
        "    \"\"\"\n",
        "    if approx_armijo:\n",
        "        armijo_fn = make_approx_armijo_ok_step(eps)\n",
        "    else:\n",
        "        armijo_fn = armijo_ok_step\n",
        "\n",
        "    def wolfe_ok_step_fn(step0: Step, step: Step, c1: float, c2: float) -> bool:\n",
        "        \"\"\"\n",
        "        Checks the Wolfe conditions for a given step.\n",
        "\n",
        "        Args:\n",
        "            step0 (Step): Initial step before the line search.\n",
        "            step (Step): Current step being evaluated.\n",
        "            c1 (float): Armijo condition constant.\n",
        "            c2 (float): Curvature condition constant.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if both conditions are satisfied, False otherwise.\n",
        "        \"\"\"\n",
        "        armijo = armijo_fn(step0, step, c1)\n",
        "        if strong_curvature:\n",
        "            # Strong Wolfe: d(alpha) >= c2 * d0\n",
        "            curvature = step.d >= c2 * step0.d\n",
        "        else:\n",
        "            # Standard Wolfe: |d(alpha)| <= c2 * |d0|\n",
        "            curvature = abs(step.d) <= c2 * abs(step0.d)\n",
        "        return armijo and curvature\n",
        "\n",
        "    return wolfe_ok_step_fn\n",
        "\n",
        "\n",
        "def quadratic_interpolate(stx: float, fx: float, dx: float,\n",
        "                         stp: float, fp: float) -> float:\n",
        "    \"\"\"\n",
        "    Performs quadratic interpolation to estimate a new step.\n",
        "\n",
        "    Args:\n",
        "        stx (float): Step size at the best step so far.\n",
        "        fx (float): Function value at stx.\n",
        "        dx (float): Directional derivative at stx.\n",
        "        stp (float): Current step size.\n",
        "        fp (float): Function value at stp.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated step size.\n",
        "    \"\"\"\n",
        "    denom = 2 * (fx - fp - dx * (stp - stx))\n",
        "    if denom == 0:\n",
        "        return (stx + stp) / 2.0\n",
        "    alpha = stx - (dx * (stp - stx) ** 2) / denom\n",
        "    return alpha\n",
        "\n",
        "\n",
        "def quadratic_interpolate_g(stp: float, dp: float,\n",
        "                           stx: float, dx: float) -> float:\n",
        "    \"\"\"\n",
        "    Performs quadratic interpolation based on derivative information.\n",
        "\n",
        "    Args:\n",
        "        stp (float): Current step size.\n",
        "        dp (float): Directional derivative at stp.\n",
        "        stx (float): Step size at the best step so far.\n",
        "        dx (float): Directional derivative at stx.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated step size.\n",
        "    \"\"\"\n",
        "    denom = dp - dx\n",
        "    if denom == 0:\n",
        "        return (stx + stp) / 2.0\n",
        "    alpha = stx - dx * (stp - stx) / denom\n",
        "    return alpha\n",
        "\n",
        "\n",
        "def cubic_interpolate(stx: float, fx: float, dx: float,\n",
        "                     stp: float, fp: float, dp: float,\n",
        "                     ignore_warnings: bool = True) -> float:\n",
        "    \"\"\"\n",
        "    Performs cubic interpolation to estimate a new step.\n",
        "\n",
        "    Args:\n",
        "        stx (float): Step size at the best step so far.\n",
        "        fx (float): Function value at stx.\n",
        "        dx (float): Directional derivative at stx.\n",
        "        stp (float): Current step size.\n",
        "        fp (float): Function value at stp.\n",
        "        dp (float): Directional derivative at stp.\n",
        "        ignore_warnings (bool): If True, returns NaN instead of raising an error.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated step size, or NaN if interpolation fails.\n",
        "    \"\"\"\n",
        "    h = stp - stx\n",
        "    if h == 0:\n",
        "        return (stx + stp) / 2.0\n",
        "\n",
        "    a = (2 * (fx - fp) + h * (dx + dp)) / h**3\n",
        "    b = (3 * (fp - fx) - h * (2 * dx + dp)) / h**2\n",
        "    c = dx\n",
        "\n",
        "    # Check if 'a' is too small to prevent division by zero\n",
        "    if np.isclose(a, 0.0):\n",
        "        if ignore_warnings:\n",
        "            return np.nan\n",
        "        else:\n",
        "            raise ValueError(\"Cubic interpolation: coefficient 'a' is zero.\")\n",
        "\n",
        "    discrim = b**2 - 3 * a * c\n",
        "    if discrim < 0:\n",
        "        if ignore_warnings:\n",
        "            return np.nan\n",
        "        else:\n",
        "            raise ValueError(\"Cubic interpolation: negative discriminant\")\n",
        "    sqrt_discrim = np.sqrt(discrim)\n",
        "    x1 = (-b + sqrt_discrim) / (3 * a)\n",
        "    x2 = (-b - sqrt_discrim) / (3 * a)\n",
        "    candidates = [x for x in [x1, x2] if 0 < x < h]\n",
        "    if not candidates:\n",
        "        if ignore_warnings:\n",
        "            return np.nan\n",
        "        else:\n",
        "            raise ValueError(\"Cubic interpolation: no valid roots\")\n",
        "    alpha_new = stx + min(candidates, key=lambda x: abs(x))\n",
        "    return alpha_new\n",
        "\n",
        "\n",
        "def ensure_min_alpha(alpha: float, x: float, y: float, minshrink: float = 0.001) -> float:\n",
        "    \"\"\"\n",
        "    Ensures that the new alpha is not too close to the interval bounds.\n",
        "\n",
        "    Args:\n",
        "        alpha (float): Suggested step size.\n",
        "        x (float): One end of the interval.\n",
        "        y (float): Other end of the interval.\n",
        "        minshrink (float): Minimum fraction of the interval range that alpha can increase by.\n",
        "\n",
        "    Returns:\n",
        "        float: Modified step size.\n",
        "    \"\"\"\n",
        "    l = min(x, y)\n",
        "    length = abs(x - y)\n",
        "    return max(l + minshrink * length, alpha)\n",
        "\n",
        "\n",
        "def modify_step(step: Step, dgtest: float) -> Step:\n",
        "    \"\"\"\n",
        "    Modifies a step based on the sufficient decrease condition.\n",
        "\n",
        "    Args:\n",
        "        step (Step): Current step.\n",
        "        dgtest (float): Product of the initial directional derivative and the sufficient decrease constant.\n",
        "\n",
        "    Returns:\n",
        "        Step: Modified step.\n",
        "    \"\"\"\n",
        "    return Step(\n",
        "        alpha=step.alpha,\n",
        "        f=step.f - step.alpha * dgtest,\n",
        "        d=step.d - dgtest\n",
        "    )\n",
        "\n",
        "\n",
        "def unmodify_step(stepm: Step, dgtest: float) -> Step:\n",
        "    \"\"\"\n",
        "    Reverses the modification of a step.\n",
        "\n",
        "    Args:\n",
        "        stepm (Step): Modified step.\n",
        "        dgtest (float): Product of the initial directional derivative and the sufficient decrease constant.\n",
        "\n",
        "    Returns:\n",
        "        Step: Unmodified step.\n",
        "    \"\"\"\n",
        "    return Step(\n",
        "        alpha=stepm.alpha,\n",
        "        f=stepm.f + stepm.alpha * dgtest,\n",
        "        d=stepm.d + dgtest\n",
        "    )\n",
        "\n",
        "\n",
        "def find_finite(phi: Callable[[float], Dict[str, float]],\n",
        "                alpha: float, maxfev: int,\n",
        "                min_alpha: Optional[float] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Evaluates phi(alpha) and ensures that the function value and derivative are finite.\n",
        "    If not, performs bisection to find a finite step size.\n",
        "\n",
        "    Args:\n",
        "        phi (Callable[[float], Dict[str, float]]): Objective function along the search direction.\n",
        "        alpha (float): Current step size.\n",
        "        maxfev (int): Maximum number of function evaluations allowed.\n",
        "        min_alpha (Optional[float]): Minimum acceptable step size.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Contains 'ok' (bool), 'step' (Step or None), and 'nfn' (int).\n",
        "    \"\"\"\n",
        "    nfn = 0\n",
        "    alpha_lower = min_alpha if min_alpha is not None else 0.0\n",
        "    step = None\n",
        "\n",
        "    while nfn < maxfev:\n",
        "        try:\n",
        "            result = phi(alpha)\n",
        "            f = result['f']\n",
        "            d = result['d']\n",
        "            if np.isfinite(f) and np.isfinite(d):\n",
        "                step = Step(alpha=alpha, f=f, d=d)\n",
        "                return {'ok': True, 'step': step, 'nfn': nfn + 1}\n",
        "        except (KeyError, TypeError):\n",
        "            # Handle specific exceptions related to phi's output\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            # Optionally, re-raise unexpected exceptions\n",
        "            raise e\n",
        "\n",
        "        # If not finite, reduce alpha by half\n",
        "        if alpha > alpha_lower:\n",
        "            alpha = (alpha + alpha_lower) / 2.0\n",
        "        else:\n",
        "            break\n",
        "        nfn += 1\n",
        "\n",
        "    return {'ok': False, 'step': None, 'nfn': nfn}\n",
        "\n",
        "\n",
        "def check_convergence(step0: Step, step: Step, brackt: bool, infoc: int,\n",
        "                     stmin: float, stmax: float,\n",
        "                     alpha_min: float, alpha_max: float,\n",
        "                     c1: float, c2: float, nfev: int,\n",
        "                     maxfev: int, xtol: float,\n",
        "                     armijo_check_fn: Callable[[Step, Step, float], bool],\n",
        "                     wolfe_ok_step_fn: Callable[[Step, Step, float, float], bool],\n",
        "                     verbose: bool = False) -> int:\n",
        "    \"\"\"\n",
        "    Checks whether the line search has converged based on various criteria.\n",
        "\n",
        "    Args:\n",
        "        step0 (Step): Initial step before the line search.\n",
        "        step (Step): Current step being evaluated.\n",
        "        brackt (bool): Whether the step has been bracketed.\n",
        "        infoc (int): Return code from the last step size update.\n",
        "        stmin (float): Smallest value of the step size interval.\n",
        "        stmax (float): Largest value of the step size interval.\n",
        "        alpha_min (float): Minimum acceptable step size.\n",
        "        alpha_max (float): Maximum acceptable step size.\n",
        "        c1 (float): Armijo condition constant.\n",
        "        c2 (float): Curvature condition constant.\n",
        "        nfev (int): Current number of function evaluations.\n",
        "        maxfev (int): Maximum number of function evaluations allowed.\n",
        "        xtol (float): Relative width tolerance.\n",
        "        armijo_check_fn (Callable[[Step, Step, float], bool]): Function to check the Armijo condition.\n",
        "        wolfe_ok_step_fn (Callable[[Step, Step, float, float], bool]): Function to check the Wolfe conditions.\n",
        "        verbose (bool): If True, prints debug information.\n",
        "\n",
        "    Returns:\n",
        "        int: Integer code indicating the convergence state.\n",
        "            0: No convergence.\n",
        "            1: The sufficient decrease condition and the directional derivative condition hold.\n",
        "            2: Relative width of the interval of uncertainty is at most xtol.\n",
        "            3: Number of calls to phi has reached maxfev.\n",
        "            4: The step is at the lower bound alpha_min.\n",
        "            5: The step is at the upper bound alpha_max.\n",
        "            6: Rounding errors prevent further progress.\n",
        "            7: Unable to create finite alpha.\n",
        "    \"\"\"\n",
        "    info = 0\n",
        "    if (brackt and (step.alpha <= stmin or step.alpha >= stmax)) or (infoc == 0):\n",
        "        if verbose:\n",
        "            print(f\"MT: Rounding errors prevent further progress: stmin = {stmin}, stmax = {stmax}\")\n",
        "        # Rounding errors prevent further progress\n",
        "        info = 6\n",
        "\n",
        "    if (step.alpha == alpha_max and armijo_check_fn(step0, step, c1) and\n",
        "            not curvature_ok_step(step0, step, c2)):\n",
        "        # Reached alpha_max\n",
        "        info = 5\n",
        "        if verbose:\n",
        "            print(\"MT: Reached alpha max\")\n",
        "\n",
        "    if (step.alpha == alpha_min and\n",
        "            (not armijo_check_fn(step0, step, c1) or\n",
        "             curvature_ok_step(step0, step, c2))):\n",
        "        # Reached alpha_min\n",
        "        info = 4\n",
        "        if verbose:\n",
        "            print(\"MT: Reached alpha min\")\n",
        "\n",
        "    if nfev >= maxfev:\n",
        "        # Maximum number of function evaluations reached\n",
        "        info = 3\n",
        "        if verbose:\n",
        "            print(\"MT: Exceeded maximum number of function evaluations\")\n",
        "\n",
        "    if brackt and (stmax - stmin) <= xtol * stmax:\n",
        "        # Interval width is below xtol\n",
        "        info = 2\n",
        "        if verbose:\n",
        "            print(f\"MT: Interval width is <= xtol: {xtol * stmax}\")\n",
        "\n",
        "    if wolfe_ok_step_fn(step0, step, c1, c2):\n",
        "        # Success\n",
        "        info = 1\n",
        "        if verbose:\n",
        "            print(\"Success! Step satisfies Wolfe conditions.\")\n",
        "\n",
        "    return info\n",
        "\n",
        "\n",
        "def cstep(stepx: Step, stepy: Step, step: Step, brackt: bool,\n",
        "          stpmin: float, stpmax: float,\n",
        "          safeguard_cubic: bool = False,\n",
        "          verbose: bool = False) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Updates the interval of uncertainty and computes a new trial step.\n",
        "\n",
        "    Args:\n",
        "        stepx (Step): One side of the updated step interval.\n",
        "        stepy (Step): Other side of the updated step interval.\n",
        "        step (Step): Current trial step.\n",
        "        brackt (bool): Whether the step has been bracketed.\n",
        "        stpmin (float): Minimum allowed step size.\n",
        "        stpmax (float): Maximum allowed step size.\n",
        "        safeguard_cubic (bool): If True, ensures the cubic step isn't too close to the bounds.\n",
        "        verbose (bool): If True, prints debug information.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Contains updated 'stepx', 'stepy', 'step', 'brackt', and 'info'.\n",
        "    \"\"\"\n",
        "    stx = stepx.alpha\n",
        "    fx = stepx.f\n",
        "    dx = stepx.d\n",
        "\n",
        "    sty = stepy.alpha\n",
        "    fy = stepy.f\n",
        "    dy = stepy.d\n",
        "\n",
        "    stp = step.alpha\n",
        "    fp = step.f\n",
        "    dp = step.d\n",
        "\n",
        "    delta = 0.66\n",
        "    info = 0\n",
        "\n",
        "    # Check the input parameters for errors\n",
        "    if (brackt and (stp <= min(stx, sty) or stp >= max(stx, sty))) or \\\n",
        "            (dx * (stp - stx) >= 0.0) or (stpmax < stpmin):\n",
        "        # Improper input parameters\n",
        "        if verbose:\n",
        "            print(\"cstep: Improper input parameters detected.\")\n",
        "        return {\n",
        "            'stepx': stepx,\n",
        "            'stepy': stepy,\n",
        "            'step': step,\n",
        "            'brackt': brackt,\n",
        "            'info': info\n",
        "        }\n",
        "\n",
        "    # Determine if the derivatives have opposite sign\n",
        "    sgnd = dp * np.sign(dx)  # Equivalent to dp * sign(dx)\n",
        "\n",
        "    # First case: fp > fx\n",
        "    if fp > fx:\n",
        "        info = 1\n",
        "        bound = True\n",
        "\n",
        "        stpc = cubic_interpolate(stx, fx, dx, stp, fp, dp, ignore_warnings=True)\n",
        "        stpq = quadratic_interpolate(stx, fx, dx, stp, fp)\n",
        "\n",
        "        if np.isnan(stpc):\n",
        "            stpf = stpq\n",
        "            if verbose:\n",
        "                print(\"cstep: Cubic interpolation failed, using quadratic interpolation.\")\n",
        "        else:\n",
        "            if abs(stpc - stx) < abs(stpq - stx):\n",
        "                if safeguard_cubic:\n",
        "                    stpf = ensure_min_alpha(stpc, stx, sty)\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using safeguarded cubic interpolation.\")\n",
        "                else:\n",
        "                    stpf = stpc\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using cubic interpolation.\")\n",
        "            else:\n",
        "                stpf = stpc + (stpq - stpc) / 2.0\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using combination of cubic and quadratic interpolation.\")\n",
        "\n",
        "        brackt = True\n",
        "\n",
        "    # Second case: sgnd < 0\n",
        "    elif sgnd < 0.0:\n",
        "        info = 2\n",
        "        bound = False\n",
        "\n",
        "        stpc = cubic_interpolate(stx, fx, dx, stp, fp, dp, ignore_warnings=True)\n",
        "        stpq = quadratic_interpolate_g(stp, dp, stx, dx)\n",
        "\n",
        "        if np.isnan(stpc):\n",
        "            stpf = stpq\n",
        "            if verbose:\n",
        "                print(\"cstep: Cubic interpolation failed, using quadratic interpolation based on derivatives.\")\n",
        "        else:\n",
        "            if abs(stpc - stp) > abs(stpq - stp):\n",
        "                if safeguard_cubic:\n",
        "                    stpf = ensure_min_alpha(stpc, stx, sty)\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using safeguarded cubic interpolation.\")\n",
        "                else:\n",
        "                    stpf = stpc\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using cubic interpolation.\")\n",
        "            else:\n",
        "                stpf = stpq\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using quadratic interpolation based on derivatives.\")\n",
        "\n",
        "        brackt = True\n",
        "\n",
        "    # Third case: |dp| < |dx|\n",
        "    elif abs(dp) < abs(dx):\n",
        "        info = 3\n",
        "        bound = True\n",
        "        theta = 3.0 * (fx - fp) / (stp - stx) + dx + dp\n",
        "        s = np.linalg.norm([theta, dx, dp], ord=np.inf)  # Infinity norm\n",
        "        gamma_sq = (theta / s)**2 - (dx / s) * (dp / s)\n",
        "        gamma = s * np.sqrt(max(0.0, gamma_sq))\n",
        "        if stp > stx:\n",
        "            gamma = -gamma\n",
        "        p = (gamma - dp) + theta\n",
        "        q = (gamma + (dx - dp)) + gamma\n",
        "        if q == 0.0:\n",
        "            r = 0.0\n",
        "        else:\n",
        "            r = p / q\n",
        "\n",
        "        if r < 0.0 and gamma != 0.0:\n",
        "            stpc = stp + r * (stx - stp)\n",
        "        elif stp > stx:\n",
        "            stpc = stpmax\n",
        "        else:\n",
        "            stpc = stpmin\n",
        "\n",
        "        stpq = quadratic_interpolate_g(stp, dp, stx, dx)\n",
        "\n",
        "        if brackt:\n",
        "            if abs(stp - stpc) < abs(stp - stpq):\n",
        "                stpf = stpc\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using cubic interpolation within bracket.\")\n",
        "            else:\n",
        "                stpf = stpq\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using quadratic interpolation within bracket.\")\n",
        "        else:\n",
        "            if abs(stp - stpc) > abs(stp - stpq):\n",
        "                stpf = stpc\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using cubic interpolation outside bracket.\")\n",
        "            else:\n",
        "                stpf = stpq\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using quadratic interpolation outside bracket.\")\n",
        "\n",
        "    # Fourth case\n",
        "    else:\n",
        "        info = 4\n",
        "        bound = False\n",
        "        if brackt:\n",
        "            stpc = cubic_interpolate(sty, fy, dy, stp, fp, dp, ignore_warnings=True)\n",
        "            if np.isnan(stpc):\n",
        "                stpc = (sty + stp) / 2.0\n",
        "                if verbose:\n",
        "                    print(\"cstep: Cubic interpolation failed within bracket, using bisection.\")\n",
        "            if safeguard_cubic:\n",
        "                stpf = ensure_min_alpha(stpc, stx, sty)\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using safeguarded cubic interpolation within bracket.\")\n",
        "            else:\n",
        "                stpf = stpc\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using cubic interpolation within bracket.\")\n",
        "        elif stp > stx:\n",
        "            stpf = stpmax\n",
        "            if verbose:\n",
        "                print(\"cstep: Using upper bound for step size.\")\n",
        "        else:\n",
        "            stpf = stpmin\n",
        "            if verbose:\n",
        "                print(\"cstep: Using lower bound for step size.\")\n",
        "\n",
        "    # Update the interval of uncertainty\n",
        "    if fp > fx:\n",
        "        stepy = Step(alpha=stp, f=fp, d=dp)\n",
        "    else:\n",
        "        if sgnd < 0.0:\n",
        "            stepy = stepx\n",
        "        stepx = Step(alpha=stp, f=fp, d=dp)\n",
        "\n",
        "    # Compute the new step and safeguard it\n",
        "    stpf = min(stpmax, stpf)\n",
        "    stpf = max(stpmin, stpf)\n",
        "    stp = stpf\n",
        "\n",
        "    if brackt and bound:\n",
        "        # If the new step is too close to an endpoint, replace with weighted bisection\n",
        "        if verbose:\n",
        "            print(\"cstep: Step too close to end point, weighted bisection\")\n",
        "        stb = stx + delta * (sty - stx)\n",
        "        if sty > stx:\n",
        "            stp = min(stb, stp)\n",
        "        else:\n",
        "            stp = max(stb, stp)\n",
        "\n",
        "    # Update step\n",
        "    step = Step(alpha=stp, f=fp, d=dp)\n",
        "\n",
        "    return {\n",
        "        'stepx': stepx,\n",
        "        'stepy': stepy,\n",
        "        'step': step,\n",
        "        'brackt': brackt,\n",
        "        'info': info\n",
        "    }\n",
        "\n",
        "\n",
        "def cvsrch(phi: Callable[[float], Dict[str, float]],\n",
        "           step0: Step, alpha: float = 1.0,\n",
        "           c1: float = 1e-4, c2: float = 0.1,\n",
        "           xtol: float = np.finfo(float).eps,\n",
        "           alpha_min: float = 0.0, alpha_max: float = np.inf,\n",
        "           maxfev: int = int(1e9), delta: float = 0.66,\n",
        "           armijo_check_fn: Callable[[Step, Step, float], bool] = armijo_ok_step,\n",
        "           wolfe_ok_step_fn: Optional[Callable[[Step, Step, float, float], bool]] = None,\n",
        "           safeguard_cubic: bool = False,\n",
        "           verbose: bool = False) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Performs the More-Thuente line search to find an acceptable step size.\n",
        "\n",
        "    Args:\n",
        "        phi (Callable[[float], Dict[str, float]]): Objective function along the search direction.\n",
        "        step0 (Step): Initial step before the line search.\n",
        "        alpha (float, optional): Initial guess for the step size. Defaults to 1.0.\n",
        "        c1 (float, optional): Armijo condition constant. Defaults to 1e-4.\n",
        "        c2 (float, optional): Curvature condition constant. Defaults to 0.1.\n",
        "        xtol (float, optional): Relative width tolerance. Defaults to machine epsilon.\n",
        "        alpha_min (float, optional): Minimum acceptable step size. Defaults to 0.0.\n",
        "        alpha_max (float, optional): Maximum acceptable step size. Defaults to infinity.\n",
        "        maxfev (int, optional): Maximum number of function evaluations allowed. Defaults to a large number.\n",
        "        delta (float, optional): Minimum fraction of the interval range that the step size must decrease by. Defaults to 0.66.\n",
        "        armijo_check_fn (Callable[[Step, Step, float], bool], optional): Function to check the Armijo condition. Defaults to `armijo_ok_step`.\n",
        "        wolfe_ok_step_fn (Optional[Callable[[Step, Step, float, float], bool]], optional): Function to check the Wolfe conditions. Must be provided.\n",
        "        safeguard_cubic (bool, optional): If True, ensures the cubic step isn't too close to the bounds. Defaults to False.\n",
        "        verbose (bool, optional): If True, prints debug information. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Contains the best step found (`step`), number of function evaluations (`nfn`), gradient evaluations (`ngr`), and termination info (`info` and `message`).\n",
        "    \"\"\"\n",
        "    if wolfe_ok_step_fn is None:\n",
        "        raise ValueError(\"wolfe_ok_step_fn must be provided\")\n",
        "\n",
        "    # Initialize\n",
        "    xtrapf = 4.0\n",
        "    infoc = 1\n",
        "\n",
        "    if maxfev == 0:\n",
        "        message = get_termination_message(3)\n",
        "        return {'step': step0, 'nfn': 0, 'ngr': 0, 'info': 3, 'message': message}\n",
        "\n",
        "    # Check that the direction is descent\n",
        "    if step0.d >= 0.0:\n",
        "        message = get_termination_message(6)\n",
        "        return {'step': step0, 'nfn': 0, 'ngr': 0, 'info': 6, 'message': message}\n",
        "\n",
        "    dgtest = c1 * step0.d\n",
        "\n",
        "    # Initialize local variables\n",
        "    bracketed = False\n",
        "    brackt = False\n",
        "    stage1 = True\n",
        "    nfev = 0\n",
        "\n",
        "    width = alpha_max - alpha_min\n",
        "    width_old = 2.0 * width\n",
        "\n",
        "    stepx = step0\n",
        "    stepy = step0\n",
        "    step = Step(alpha=alpha, f=np.nan, d=np.nan)  # To be filled by find_finite\n",
        "\n",
        "    while True:\n",
        "        # Set the minimum and maximum steps to correspond to the present interval of uncertainty\n",
        "        if brackt:\n",
        "            stmin = min(stepx.alpha, stepy.alpha)\n",
        "            stmax = max(stepx.alpha, stepy.alpha)\n",
        "        else:\n",
        "            stmin = stepx.alpha\n",
        "            # Handle cases where step.alpha might be NaN initially\n",
        "            if np.isnan(step.alpha):\n",
        "                stmax = alpha_max\n",
        "            else:\n",
        "                stmax = step.alpha + xtrapf * (step.alpha - stepx.alpha)\n",
        "\n",
        "        # Force the step to be within the bounds alpha_max and alpha_min\n",
        "        if not np.isnan(step.alpha):\n",
        "            step.alpha = max(step.alpha, alpha_min)\n",
        "            step.alpha = min(step.alpha, alpha_max)\n",
        "        else:\n",
        "            step.alpha = alpha_min\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Bracket: [{stmin}, {stmax}] alpha = {step.alpha}\")\n",
        "\n",
        "        # Evaluate the function and gradient at alpha\n",
        "        # and compute the directional derivative\n",
        "        ffres = find_finite(phi, step.alpha, maxfev - nfev, min_alpha=stmin)\n",
        "        nfev += ffres['nfn']\n",
        "        if not ffres['ok']:\n",
        "            if verbose:\n",
        "                print(\"Unable to create finite alpha\")\n",
        "            message = get_termination_message(7)\n",
        "            return {'step': step0, 'nfn': nfev, 'ngr': nfev, 'info': 7, 'message': message}\n",
        "        step = ffres['step']\n",
        "\n",
        "        # Test for convergence\n",
        "        info = check_convergence(step0, step, brackt, infoc, stmin, stmax,\n",
        "                                 alpha_min, alpha_max, c1, c2, nfev,\n",
        "                                 maxfev, xtol,\n",
        "                                 armijo_check_fn=armijo_check_fn,\n",
        "                                 wolfe_ok_step_fn=wolfe_ok_step_fn,\n",
        "                                 verbose=verbose)\n",
        "\n",
        "        # Check for termination\n",
        "        if info != 0:\n",
        "            # If an unusual termination is to occur, then set step to the best step found\n",
        "            if info in [2, 3, 6]:\n",
        "                step = stepx\n",
        "            message = get_termination_message(info)\n",
        "            if verbose:\n",
        "                print(f\"alpha = {step.alpha}\")\n",
        "            return {'step': step, 'nfn': nfev, 'ngr': nfev, 'info': info, 'message': message}\n",
        "\n",
        "        # In the first stage we seek a step for which the modified\n",
        "        # function has a nonpositive value and nonnegative derivative\n",
        "        if stage1 and wolfe_ok_step_fn(step0, step, c1, min(c1, c2)):\n",
        "            stage1 = False\n",
        "\n",
        "        # A modified function is used to predict the step only if\n",
        "        # we have not obtained a step for which the modified\n",
        "        # function has a nonpositive function value and nonnegative\n",
        "        # derivative, and if a lower function value has been\n",
        "        # obtained but the decrease is not sufficient\n",
        "        if stage1 and step.f <= stepx.f and not armijo_check_fn(step0, step, c1):\n",
        "            # Define the modified function and derivative values\n",
        "            stepxm = modify_step(stepx, dgtest)\n",
        "            stepym = modify_step(stepy, dgtest)\n",
        "            stepm = modify_step(step, dgtest)\n",
        "\n",
        "            step_result = cstep(stepxm, stepym, stepm, brackt, stmin, stmax,\n",
        "                                safeguard_cubic=safeguard_cubic,\n",
        "                                verbose=verbose)\n",
        "\n",
        "            brackt = step_result['brackt']\n",
        "            infoc = step_result['info']\n",
        "            stepxm = step_result['stepx']\n",
        "            stepym = step_result['stepy']\n",
        "            stepm = step_result['step']\n",
        "\n",
        "            # Reset the function and gradient values for f\n",
        "            stepx = unmodify_step(stepxm, dgtest)\n",
        "            stepy = unmodify_step(stepym, dgtest)\n",
        "            step = Step(alpha=stepm.alpha,\n",
        "                        f=stepm.f + stepm.alpha * dgtest,\n",
        "                        d=stepm.d + dgtest)\n",
        "        else:\n",
        "            # Call cstep to update the interval of uncertainty\n",
        "            # and to compute the new step.\n",
        "            step_result = cstep(stepx, stepy, step, brackt, stmin, stmax,\n",
        "                                safeguard_cubic=safeguard_cubic,\n",
        "                                verbose=verbose)\n",
        "            brackt = step_result['brackt']\n",
        "            infoc = step_result['info']\n",
        "            stepx = step_result['stepx']\n",
        "            stepy = step_result['stepy']\n",
        "            step = step_result['step']\n",
        "\n",
        "        if not bracketed and brackt:\n",
        "            bracketed = True\n",
        "            if verbose:\n",
        "                print(\"Bracketed\")\n",
        "\n",
        "        # Force a sufficient decrease in the size of the interval of uncertainty\n",
        "        if brackt:\n",
        "            width_new = abs(stepy.alpha - stepx.alpha)\n",
        "            if width_new >= delta * width_old:\n",
        "                if verbose:\n",
        "                    print(\"Interval did not decrease sufficiently: bisecting\")\n",
        "                step.alpha = stepx.alpha + 0.5 * (stepy.alpha - stepx.alpha)\n",
        "            width_old = width\n",
        "            width = width_new\n",
        "\n",
        "\n",
        "def check_convergence(step0: Step, step: Step, brackt: bool, infoc: int,\n",
        "                     stmin: float, stmax: float,\n",
        "                     alpha_min: float, alpha_max: float,\n",
        "                     c1: float, c2: float, nfev: int,\n",
        "                     maxfev: int, xtol: float,\n",
        "                     armijo_check_fn: Callable[[Step, Step, float], bool],\n",
        "                     wolfe_ok_step_fn: Callable[[Step, Step, float, float], bool],\n",
        "                     verbose: bool = False) -> int:\n",
        "    \"\"\"\n",
        "    Checks whether the line search has converged based on various criteria.\n",
        "\n",
        "    Args:\n",
        "        step0 (Step): Initial step before the line search.\n",
        "        step (Step): Current step being evaluated.\n",
        "        brackt (bool): Whether the step has been bracketed.\n",
        "        infoc (int): Return code from the last step size update.\n",
        "        stmin (float): Smallest value of the step size interval.\n",
        "        stmax (float): Largest value of the step size interval.\n",
        "        alpha_min (float): Minimum acceptable step size.\n",
        "        alpha_max (float): Maximum acceptable step size.\n",
        "        c1 (float): Armijo condition constant.\n",
        "        c2 (float): Curvature condition constant.\n",
        "        nfev (int): Current number of function evaluations.\n",
        "        maxfev (int): Maximum number of function evaluations allowed.\n",
        "        xtol (float): Relative width tolerance.\n",
        "        armijo_check_fn (Callable[[Step, Step, float], bool]): Function to check the Armijo condition.\n",
        "        wolfe_ok_step_fn (Callable[[Step, Step, float, float], bool]): Function to check the Wolfe conditions.\n",
        "        verbose (bool): If True, prints debug information.\n",
        "\n",
        "    Returns:\n",
        "        int: Integer code indicating the convergence state.\n",
        "            0: No convergence.\n",
        "            1: The sufficient decrease condition and the directional derivative condition hold.\n",
        "            2: Relative width of the interval of uncertainty is at most xtol.\n",
        "            3: Number of calls to phi has reached maxfev.\n",
        "            4: The step is at the lower bound alpha_min.\n",
        "            5: The step is at the upper bound alpha_max.\n",
        "            6: Rounding errors prevent further progress.\n",
        "            7: Unable to create finite alpha.\n",
        "    \"\"\"\n",
        "    info = 0\n",
        "    if (brackt and (step.alpha <= stmin or step.alpha >= stmax)) or (infoc == 0):\n",
        "        if verbose:\n",
        "            print(f\"MT: Rounding errors prevent further progress: stmin = {stmin}, stmax = {stmax}\")\n",
        "        # Rounding errors prevent further progress\n",
        "        info = 6\n",
        "\n",
        "    if (step.alpha == alpha_max and armijo_check_fn(step0, step, c1) and\n",
        "            not curvature_ok_step(step0, step, c2)):\n",
        "        # Reached alpha_max\n",
        "        info = 5\n",
        "        if verbose:\n",
        "            print(\"MT: Reached alpha max\")\n",
        "\n",
        "    if (step.alpha == alpha_min and\n",
        "            (not armijo_check_fn(step0, step, c1) or\n",
        "             curvature_ok_step(step0, step, c2))):\n",
        "        # Reached alpha_min\n",
        "        info = 4\n",
        "        if verbose:\n",
        "            print(\"MT: Reached alpha min\")\n",
        "\n",
        "    if nfev >= maxfev:\n",
        "        # Maximum number of function evaluations reached\n",
        "        info = 3\n",
        "        if verbose:\n",
        "            print(\"MT: Exceeded maximum number of function evaluations\")\n",
        "\n",
        "    if brackt and (stmax - stmin) <= xtol * stmax:\n",
        "        # Interval width is below xtol\n",
        "        info = 2\n",
        "        if verbose:\n",
        "            print(f\"MT: Interval width is <= xtol: {xtol * stmax}\")\n",
        "\n",
        "    if wolfe_ok_step_fn(step0, step, c1, c2):\n",
        "        # Success\n",
        "        info = 1\n",
        "        if verbose:\n",
        "            print(\"Success! Step satisfies Wolfe conditions.\")\n",
        "\n",
        "    return info\n",
        "\n",
        "\n",
        "def cstep(stepx: Step, stepy: Step, step: Step, brackt: bool,\n",
        "          stpmin: float, stpmax: float,\n",
        "          safeguard_cubic: bool = False,\n",
        "          verbose: bool = False) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Updates the interval of uncertainty and computes a new trial step.\n",
        "\n",
        "    Args:\n",
        "        stepx (Step): One side of the updated step interval.\n",
        "        stepy (Step): Other side of the updated step interval.\n",
        "        step (Step): Current trial step.\n",
        "        brackt (bool): Whether the step has been bracketed.\n",
        "        stpmin (float): Minimum allowed step size.\n",
        "        stpmax (float): Maximum allowed step size.\n",
        "        safeguard_cubic (bool): If True, ensures the cubic step isn't too close to the bounds.\n",
        "        verbose (bool): If True, prints debug information.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Contains updated 'stepx', 'stepy', 'step', 'brackt', and 'info'.\n",
        "    \"\"\"\n",
        "    stx = stepx.alpha\n",
        "    fx = stepx.f\n",
        "    dx = stepx.d\n",
        "\n",
        "    sty = stepy.alpha\n",
        "    fy = stepy.f\n",
        "    dy = stepy.d\n",
        "\n",
        "    stp = step.alpha\n",
        "    fp = step.f\n",
        "    dp = step.d\n",
        "\n",
        "    delta = 0.66\n",
        "    info = 0\n",
        "\n",
        "    # Check the input parameters for errors\n",
        "    if (brackt and (stp <= min(stx, sty) or stp >= max(stx, sty))) or \\\n",
        "            (dx * (stp - stx) >= 0.0) or (stpmax < stpmin):\n",
        "        # Improper input parameters\n",
        "        if verbose:\n",
        "            print(\"cstep: Improper input parameters detected.\")\n",
        "        return {\n",
        "            'stepx': stepx,\n",
        "            'stepy': stepy,\n",
        "            'step': step,\n",
        "            'brackt': brackt,\n",
        "            'info': info\n",
        "        }\n",
        "\n",
        "    # Determine if the derivatives have opposite sign\n",
        "    sgnd = dp * np.sign(dx)  # Equivalent to dp * sign(dx)\n",
        "\n",
        "    # First case: fp > fx\n",
        "    if fp > fx:\n",
        "        info = 1\n",
        "        bound = True\n",
        "\n",
        "        stpc = cubic_interpolate(stx, fx, dx, stp, fp, dp, ignore_warnings=True)\n",
        "        stpq = quadratic_interpolate(stx, fx, dx, stp, fp)\n",
        "\n",
        "        if np.isnan(stpc):\n",
        "            stpf = stpq\n",
        "            if verbose:\n",
        "                print(\"cstep: Cubic interpolation failed, using quadratic interpolation.\")\n",
        "        else:\n",
        "            if abs(stpc - stx) < abs(stpq - stx):\n",
        "                if safeguard_cubic:\n",
        "                    stpf = ensure_min_alpha(stpc, stx, sty)\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using safeguarded cubic interpolation.\")\n",
        "                else:\n",
        "                    stpf = stpc\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using cubic interpolation.\")\n",
        "            else:\n",
        "                stpf = stpc + (stpq - stpc) / 2.0\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using combination of cubic and quadratic interpolation.\")\n",
        "\n",
        "        brackt = True\n",
        "\n",
        "    # Second case: sgnd < 0\n",
        "    elif sgnd < 0.0:\n",
        "        info = 2\n",
        "        bound = False\n",
        "\n",
        "        stpc = cubic_interpolate(stx, fx, dx, stp, fp, dp, ignore_warnings=True)\n",
        "        stpq = quadratic_interpolate_g(stp, dp, stx, dx)\n",
        "\n",
        "        if np.isnan(stpc):\n",
        "            stpf = stpq\n",
        "            if verbose:\n",
        "                print(\"cstep: Cubic interpolation failed, using quadratic interpolation based on derivatives.\")\n",
        "        else:\n",
        "            if abs(stpc - stp) > abs(stpq - stp):\n",
        "                if safeguard_cubic:\n",
        "                    stpf = ensure_min_alpha(stpc, stx, sty)\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using safeguarded cubic interpolation.\")\n",
        "                else:\n",
        "                    stpf = stpc\n",
        "                    if verbose:\n",
        "                        print(\"cstep: Using cubic interpolation.\")\n",
        "            else:\n",
        "                stpf = stpq\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using quadratic interpolation based on derivatives.\")\n",
        "\n",
        "        brackt = True\n",
        "\n",
        "    # Third case: |dp| < |dx|\n",
        "    elif abs(dp) < abs(dx):\n",
        "        info = 3\n",
        "        bound = True\n",
        "        theta = 3.0 * (fx - fp) / (stp - stx) + dx + dp\n",
        "        s = np.linalg.norm([theta, dx, dp], ord=np.inf)  # Infinity norm\n",
        "        gamma_sq = (theta / s)**2 - (dx / s) * (dp / s)\n",
        "        gamma = s * np.sqrt(max(0.0, gamma_sq))\n",
        "        if stp > stx:\n",
        "            gamma = -gamma\n",
        "        p = (gamma - dp) + theta\n",
        "        q = (gamma + (dx - dp)) + gamma\n",
        "        if q == 0.0:\n",
        "            r = 0.0\n",
        "        else:\n",
        "            r = p / q\n",
        "\n",
        "        if r < 0.0 and gamma != 0.0:\n",
        "            stpc = stp + r * (stx - stp)\n",
        "        elif stp > stx:\n",
        "            stpc = stpmax\n",
        "        else:\n",
        "            stpc = stpmin\n",
        "\n",
        "        stpq = quadratic_interpolate_g(stp, dp, stx, dx)\n",
        "\n",
        "        if brackt:\n",
        "            if abs(stp - stpc) < abs(stp - stpq):\n",
        "                stpf = stpc\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using cubic interpolation within bracket.\")\n",
        "            else:\n",
        "                stpf = stpq\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using quadratic interpolation within bracket.\")\n",
        "        else:\n",
        "            if abs(stp - stpc) > abs(stp - stpq):\n",
        "                stpf = stpc\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using cubic interpolation outside bracket.\")\n",
        "            else:\n",
        "                stpf = stpq\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using quadratic interpolation outside bracket.\")\n",
        "\n",
        "    # Fourth case\n",
        "    else:\n",
        "        info = 4\n",
        "        bound = False\n",
        "        if brackt:\n",
        "            stpc = cubic_interpolate(sty, fy, dy, stp, fp, dp, ignore_warnings=True)\n",
        "            if np.isnan(stpc):\n",
        "                stpc = (sty + stp) / 2.0\n",
        "                if verbose:\n",
        "                    print(\"cstep: Cubic interpolation failed within bracket, using bisection.\")\n",
        "            if safeguard_cubic:\n",
        "                stpf = ensure_min_alpha(stpc, stx, sty)\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using safeguarded cubic interpolation within bracket.\")\n",
        "            else:\n",
        "                stpf = stpc\n",
        "                if verbose:\n",
        "                    print(\"cstep: Using cubic interpolation within bracket.\")\n",
        "        elif stp > stx:\n",
        "            stpf = stpmax\n",
        "            if verbose:\n",
        "                print(\"cstep: Using upper bound for step size.\")\n",
        "        else:\n",
        "            stpf = stpmin\n",
        "            if verbose:\n",
        "                print(\"cstep: Using lower bound for step size.\")\n",
        "\n",
        "    # Update the interval of uncertainty\n",
        "    if fp > fx:\n",
        "        stepy = Step(alpha=stp, f=fp, d=dp)\n",
        "    else:\n",
        "        if sgnd < 0.0:\n",
        "            stepy = stepx\n",
        "        stepx = Step(alpha=stp, f=fp, d=dp)\n",
        "\n",
        "    # Compute the new step and safeguard it\n",
        "    stpf = min(stpmax, stpf)\n",
        "    stpf = max(stpmin, stpf)\n",
        "    stp = stpf\n",
        "\n",
        "    if brackt and bound:\n",
        "        # If the new step is too close to an endpoint, replace with weighted bisection\n",
        "        if verbose:\n",
        "            print(\"cstep: Step too close to end point, weighted bisection\")\n",
        "        stb = stx + delta * (sty - stx)\n",
        "        if sty > stx:\n",
        "            stp = min(stb, stp)\n",
        "        else:\n",
        "            stp = max(stb, stp)\n",
        "\n",
        "    # Update step\n",
        "    step = Step(alpha=stp, f=fp, d=dp)\n",
        "\n",
        "    return {\n",
        "        'stepx': stepx,\n",
        "        'stepy': stepy,\n",
        "        'step': step,\n",
        "        'brackt': brackt,\n",
        "        'info': info\n",
        "    }\n",
        "\n",
        "\n",
        "def cvsrch(phi: Callable[[float], Dict[str, float]],\n",
        "           step0: Step, alpha: float = 1.0,\n",
        "           c1: float = 1e-4, c2: float = 0.1,\n",
        "           xtol: float = np.finfo(float).eps,\n",
        "           alpha_min: float = 0.0, alpha_max: float = np.inf,\n",
        "           maxfev: int = int(1e9), delta: float = 0.66,\n",
        "           armijo_check_fn: Callable[[Step, Step, float], bool] = armijo_ok_step,\n",
        "           wolfe_ok_step_fn: Optional[Callable[[Step, Step, float, float], bool]] = None,\n",
        "           safeguard_cubic: bool = False,\n",
        "           verbose: bool = False) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Performs the More-Thuente line search to find an acceptable step size.\n",
        "\n",
        "    Args:\n",
        "        phi (Callable[[float], Dict[str, float]]): Objective function along the search direction.\n",
        "        step0 (Step): Initial step before the line search.\n",
        "        alpha (float, optional): Initial guess for the step size. Defaults to 1.0.\n",
        "        c1 (float, optional): Armijo condition constant. Defaults to 1e-4.\n",
        "        c2 (float, optional): Curvature condition constant. Defaults to 0.1.\n",
        "        xtol (float, optional): Relative width tolerance. Defaults to machine epsilon.\n",
        "        alpha_min (float, optional): Minimum acceptable step size. Defaults to 0.0.\n",
        "        alpha_max (float, optional): Maximum acceptable step size. Defaults to infinity.\n",
        "        maxfev (int, optional): Maximum number of function evaluations allowed. Defaults to a large number.\n",
        "        delta (float, optional): Minimum fraction of the interval range that the step size must decrease by. Defaults to 0.66.\n",
        "        armijo_check_fn (Callable[[Step, Step, float], bool], optional): Function to check the Armijo condition. Defaults to `armijo_ok_step`.\n",
        "        wolfe_ok_step_fn (Optional[Callable[[Step, Step, float, float], bool]], optional): Function to check the Wolfe conditions. Must be provided.\n",
        "        safeguard_cubic (bool, optional): If True, ensures the cubic step isn't too close to the bounds. Defaults to False.\n",
        "        verbose (bool, optional): If True, prints debug information. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Contains the best step found (`step`), number of function evaluations (`nfn`),\n",
        "                        gradient evaluations (`ngr`), and termination info (`info` and `message`).\n",
        "    \"\"\"\n",
        "    if wolfe_ok_step_fn is None:\n",
        "        raise ValueError(\"wolfe_ok_step_fn must be provided\")\n",
        "\n",
        "    # Initialize\n",
        "    xtrapf = 4.0\n",
        "    infoc = 1\n",
        "\n",
        "    if maxfev == 0:\n",
        "        message = get_termination_message(3)\n",
        "        return {'step': step0, 'nfn': 0, 'ngr': 0, 'info': 3, 'message': message}\n",
        "\n",
        "    # Check that the direction is descent\n",
        "    if step0.d >= 0.0:\n",
        "        message = get_termination_message(6)\n",
        "        return {'step': step0, 'nfn': 0, 'ngr': 0, 'info': 6, 'message': message}\n",
        "\n",
        "    dgtest = c1 * step0.d\n",
        "\n",
        "    # Initialize local variables\n",
        "    bracketed = False\n",
        "    brackt = False\n",
        "    stage1 = True\n",
        "    nfev = 0\n",
        "\n",
        "    width = alpha_max - alpha_min\n",
        "    width_old = 2.0 * width\n",
        "\n",
        "    stepx = step0\n",
        "    stepy = step0\n",
        "    step = Step(alpha=alpha, f=np.nan, d=np.nan)  # To be filled by find_finite\n",
        "\n",
        "    while True:\n",
        "        # Set the minimum and maximum steps to correspond to the present interval of uncertainty\n",
        "        if brackt:\n",
        "            stmin = min(stepx.alpha, stepy.alpha)\n",
        "            stmax = max(stepx.alpha, stepy.alpha)\n",
        "        else:\n",
        "            stmin = stepx.alpha\n",
        "            # Handle cases where step.alpha might be NaN initially\n",
        "            if np.isnan(step.alpha):\n",
        "                stmax = alpha_max\n",
        "            else:\n",
        "                stmax = step.alpha + xtrapf * (step.alpha - stepx.alpha)\n",
        "\n",
        "        # Force the step to be within the bounds alpha_max and alpha_min\n",
        "        if not np.isnan(step.alpha):\n",
        "            step.alpha = max(step.alpha, alpha_min)\n",
        "            step.alpha = min(step.alpha, alpha_max)\n",
        "        else:\n",
        "            step.alpha = alpha_min\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Bracket: [{stmin}, {stmax}] alpha = {step.alpha}\")\n",
        "\n",
        "        # Evaluate the function and gradient at alpha\n",
        "        # and compute the directional derivative\n",
        "        ffres = find_finite(phi, step.alpha, maxfev - nfev, min_alpha=stmin)\n",
        "        nfev += ffres['nfn']\n",
        "        if not ffres['ok']:\n",
        "            if verbose:\n",
        "                print(\"Unable to create finite alpha\")\n",
        "            message = get_termination_message(7)\n",
        "            return {'step': step0, 'nfn': nfev, 'ngr': nfev, 'info': 7, 'message': message}\n",
        "        step = ffres['step']\n",
        "\n",
        "        # Test for convergence\n",
        "        info = check_convergence(step0, step, brackt, infoc, stmin, stmax,\n",
        "                                 alpha_min, alpha_max, c1, c2, nfev,\n",
        "                                 maxfev, xtol,\n",
        "                                 armijo_check_fn=armijo_check_fn,\n",
        "                                 wolfe_ok_step_fn=wolfe_ok_step_fn,\n",
        "                                 verbose=verbose)\n",
        "\n",
        "        # Check for termination\n",
        "        if info != 0:\n",
        "            # If an unusual termination is to occur, then set step to the best step found\n",
        "            if info in [2, 3, 6]:\n",
        "                step = stepx\n",
        "            message = get_termination_message(info)\n",
        "            if verbose:\n",
        "                print(f\"alpha = {step.alpha}\")\n",
        "            return {'step': step, 'nfn': nfev, 'ngr': nfev, 'info': info, 'message': message}\n",
        "\n",
        "        # In the first stage we seek a step for which the modified\n",
        "        # function has a nonpositive value and nonnegative derivative\n",
        "        if stage1 and wolfe_ok_step_fn(step0, step, c1, min(c1, c2)):\n",
        "            stage1 = False\n",
        "\n",
        "        # A modified function is used to predict the step only if\n",
        "        # we have not obtained a step for which the modified\n",
        "        # function has a nonpositive function value and nonnegative\n",
        "        # derivative, and if a lower function value has been\n",
        "        # obtained but the decrease is not sufficient\n",
        "        if stage1 and step.f <= stepx.f and not armijo_check_fn(step0, step, c1):\n",
        "            # Define the modified function and derivative values\n",
        "            stepxm = modify_step(stepx, dgtest)\n",
        "            stepym = modify_step(stepy, dgtest)\n",
        "            stepm = modify_step(step, dgtest)\n",
        "\n",
        "            step_result = cstep(stepxm, stepym, stepm, brackt, stmin, stmax,\n",
        "                                safeguard_cubic=safeguard_cubic,\n",
        "                                verbose=verbose)\n",
        "\n",
        "            brackt = step_result['brackt']\n",
        "            infoc = step_result['info']\n",
        "            stepxm = step_result['stepx']\n",
        "            stepym = step_result['stepy']\n",
        "            stepm = step_result['step']\n",
        "\n",
        "            # Reset the function and gradient values for f\n",
        "            stepx = unmodify_step(stepxm, dgtest)\n",
        "            stepy = unmodify_step(stepym, dgtest)\n",
        "            step = Step(alpha=stepm.alpha,\n",
        "                        f=stepm.f + stepm.alpha * dgtest,\n",
        "                        d=stepm.d + dgtest)\n",
        "        else:\n",
        "            # Call cstep to update the interval of uncertainty\n",
        "            # and to compute the new step\n",
        "            step_result = cstep(stepx, stepy, step, brackt, stmin, stmax,\n",
        "                                safeguard_cubic=safeguard_cubic,\n",
        "                                verbose=verbose)\n",
        "            brackt = step_result['brackt']\n",
        "            infoc = step_result['info']\n",
        "            stepx = step_result['stepx']\n",
        "            stepy = step_result['stepy']\n",
        "            step = step_result['step']\n",
        "\n",
        "        if not bracketed and brackt:\n",
        "            bracketed = True\n",
        "            if verbose:\n",
        "                print(\"Bracketed\")\n",
        "\n",
        "        # Force a sufficient decrease in the size of the interval of uncertainty\n",
        "        if brackt:\n",
        "            width_new = abs(stepy.alpha - stepx.alpha)\n",
        "            if width_new >= delta * width_old:\n",
        "                if verbose:\n",
        "                    print(\"Interval did not decrease sufficiently: bisecting\")\n",
        "                step.alpha = stepx.alpha + 0.5 * (stepy.alpha - stepx.alpha)\n",
        "            width_old = width\n",
        "            width = width_new\n",
        "\n",
        "\n",
        "def more_thuente(c1: float = 1e-4, c2: float = 0.1,\n",
        "                max_fn: float = np.inf, eps: float = 1e-6,\n",
        "                alpha_max: float = np.inf,\n",
        "                approx_armijo: bool = False,\n",
        "                strong_curvature: bool = True,\n",
        "                safeguard_cubic: bool = False,\n",
        "                verbose: bool = False) -> Callable[..., Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Factory function that creates a More-Thuente line search function.\n",
        "\n",
        "    Args:\n",
        "        c1 (float, optional): Armijo condition constant. Defaults to 1e-4.\n",
        "        c2 (float, optional): Curvature condition constant. Defaults to 0.1.\n",
        "        max_fn (float, optional): Maximum number of function evaluations allowed. Defaults to infinity.\n",
        "        eps (float, optional): Tolerance for approximate Armijo condition. Defaults to 1e-6.\n",
        "        alpha_max (float, optional): Maximum acceptable step size. Defaults to infinity.\n",
        "        approx_armijo (bool, optional): If True, uses an approximate Armijo condition. Defaults to False.\n",
        "        strong_curvature (bool, optional): If True, checks the strong Wolfe curvature condition. Defaults to True.\n",
        "        safeguard_cubic (bool, optional): If True, ensures the cubic step isn't too close to the bounds. Defaults to False.\n",
        "        verbose (bool, optional): If True, prints debug information. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Callable[..., Dict[str, Any]]: A line search function that can be called with specific arguments.\n",
        "    \"\"\"\n",
        "    if approx_armijo:\n",
        "        armijo_check_fn = make_approx_armijo_ok_step(eps)\n",
        "    else:\n",
        "        armijo_check_fn = armijo_ok_step\n",
        "\n",
        "    wolfe_ok_step_fn = make_wolfe_ok_step_fn(\n",
        "        strong_curvature=strong_curvature,\n",
        "        approx_armijo=approx_armijo,\n",
        "        eps=eps\n",
        "    )\n",
        "\n",
        "    def line_search(phi: Callable[[float], Dict[str, float]],\n",
        "                   step0: Step, alpha: float = 1.0,\n",
        "                   total_max_fn: float = np.inf,\n",
        "                   total_max_gr: float = np.inf,\n",
        "                   total_max_fg: float = np.inf,\n",
        "                   pm: Optional[Any] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Executes the line search.\n",
        "\n",
        "        Args:\n",
        "            phi (Callable[[float], Dict[str, float]]): Objective function along the search direction.\n",
        "            step0 (Step): Initial step before the line search.\n",
        "            alpha (float, optional): Initial guess for the step size. Defaults to 1.0.\n",
        "            total_max_fn (float, optional): Maximum function evaluations from external limits. Defaults to infinity.\n",
        "            total_max_gr (float, optional): Maximum gradient evaluations from external limits. Defaults to infinity.\n",
        "            total_max_fg (float, optional): Maximum function and gradient evaluations combined. Defaults to infinity.\n",
        "            pm (Optional[Any], optional): Additional parameters (unused).\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: Contains the best step found (`step`), number of function evaluations (`nfn`),\n",
        "                            gradient evaluations (`ngr`), and termination info (`info` and `message`).\n",
        "        \"\"\"\n",
        "        maxfev = min(max_fn, total_max_fn, total_max_gr, int(total_max_fg / 2))\n",
        "        if maxfev <= 0:\n",
        "            message = get_termination_message(3)\n",
        "            return {'step': step0, 'nfn': 0, 'ngr': 0, 'info': 3, 'message': message}\n",
        "        res = cvsrch(phi, step0,\n",
        "                     alpha=alpha, c1=c1, c2=c2,\n",
        "                     maxfev=maxfev, alpha_max=alpha_max,\n",
        "                     armijo_check_fn=armijo_check_fn,\n",
        "                     wolfe_ok_step_fn=wolfe_ok_step_fn,\n",
        "                     safeguard_cubic=safeguard_cubic,\n",
        "                     verbose=verbose)\n",
        "        return {'step': res['step'], 'nfn': res['nfn'], 'ngr': res['nfn'], 'info': res['info'], 'message': get_termination_message(res['info'])}\n",
        "\n",
        "    return line_search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Define the objective function and its derivative along the search direction\n",
        "    def phi(alpha: float) -> Dict[str, float]:\n",
        "        # Quadratic function f(alpha) = (x0 + alpha * p)^2\n",
        "        x0 = 1.0  # Starting point\n",
        "        p = -2.0  # Search direction (e.g., negative gradient)\n",
        "        x = x0 + alpha * p\n",
        "        f = x ** 2\n",
        "        d = 2 * x * p  # Directional derivative\n",
        "        return {'f': f, 'd': d}\n",
        "\n",
        "    # Initialize step0\n",
        "    initial_phi = phi(0.0)\n",
        "    step0 = Step(alpha=0.0, f=initial_phi['f'], d=initial_phi['d'])\n",
        "\n",
        "    # Create the line search function\n",
        "    line_search = more_thuente(c1=1e-4, c2=0.9, max_fn=20, verbose=True)\n",
        "\n",
        "    # Perform the line search\n",
        "    result = line_search(\n",
        "        phi=phi,\n",
        "        step0=step0,\n",
        "        alpha=1.0,\n",
        "        total_max_fn=100,\n",
        "        total_max_gr=100,\n",
        "        total_max_fg=200,\n",
        "        pm=None\n",
        "    )\n",
        "\n",
        "    # Access the results\n",
        "    best_step = result['step']\n",
        "    function_evals = result['nfn']\n",
        "    termination_info = result['info']\n",
        "    termination_message = result['message']\n",
        "\n",
        "    print(\"\\nLine Search Result:\")\n",
        "    print(f\"Best step size: {best_step.alpha}\")\n",
        "    print(f\"Function value at best step: {best_step.f}\")\n",
        "    print(f\"Directional derivative at best step: {best_step.d}\")\n",
        "    print(f\"Number of function evaluations: {function_evals}\")\n",
        "    print(f\"Termination info code: {termination_info}\")\n",
        "    print(f\"Termination Reason: {termination_message}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwg4onMLiN5T",
        "outputId": "f3de2cb9-e143-4dfc-ca6f-8a3f450c97b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bracket: [0.0, 5.0] alpha = 1.0\n",
            "cstep: Cubic interpolation failed, using quadratic interpolation.\n",
            "cstep: Step too close to end point, weighted bisection\n",
            "Bracketed\n",
            "Bracket: [0.0, 1.0] alpha = 0.5000500100020004\n",
            "Success! Step satisfies Wolfe conditions.\n",
            "alpha = 0.5000500100020004\n",
            "\n",
            "Line Search Result:\n",
            "Best step size: 0.5000500100020004\n",
            "Function value at best step: 1.0004001200337887e-08\n",
            "Directional derivative at best step: 0.0004000800160035567\n",
            "Number of function evaluations: 2\n",
            "Termination info code: 1\n",
            "Termination Reason: The sufficient decrease condition and the directional derivative condition hold.\n"
          ]
        }
      ]
    }
  ]
}
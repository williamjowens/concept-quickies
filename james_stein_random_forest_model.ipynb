{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Setup"
      ],
      "metadata": {
        "id": "23ld02OahiFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from joblib import Parallel, delayed\n",
        "from collections import deque\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "J5WMcR7Vhqa-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSDT"
      ],
      "metadata": {
        "id": "5Up4PbQNjkQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JamesSteinDecisionTreeRegressor:\n",
        "    \"\"\"\n",
        "    James-Stein Decision Tree Regressor (single tree).\n",
        "    Supports 'P', 'C', 'CP' variants of James-Stein shrinkage.\n",
        "\n",
        "    Evaluates splits by SSE, but final performance uses RMSE in cross-validation.\n",
        "    \"\"\"\n",
        "\n",
        "    class Node:\n",
        "        \"\"\"\n",
        "        Represents a node in the decision tree.\n",
        "\n",
        "        Attributes:\n",
        "            left (Node): Left child node.\n",
        "            right (Node): Right child node.\n",
        "            feature_index (int): Index of the feature used for splitting.\n",
        "            threshold (float): Threshold value for splitting.\n",
        "            prediction (float): Local mean or JS-adjusted mean at the node.\n",
        "            depth (int): Depth of this node.\n",
        "            n_samples (int): Number of samples in this node.\n",
        "            variance (float): Unbiased variance of this node's target values.\n",
        "        \"\"\"\n",
        "        def __init__(self, depth=0, max_depth=None):\n",
        "            self.left = None\n",
        "            self.right = None\n",
        "            self.feature_index = None\n",
        "            self.threshold = None\n",
        "            self.prediction = None\n",
        "            self.depth = depth\n",
        "            self.max_depth = max_depth\n",
        "            self.n_samples = 0\n",
        "            self.variance = 0.0\n",
        "\n",
        "    def __init__(self, variant='P', max_depth=None, min_samples_split=2, lambda_param=1.0):\n",
        "        if variant not in ['P', 'C', 'CP']:\n",
        "            raise ValueError(\"variant must be one of ['P','C','CP'].\")\n",
        "        self.variant = variant\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.lambda_param = lambda_param\n",
        "\n",
        "        # Internal variables\n",
        "        self.root = None\n",
        "        self.leaf_nodes = []\n",
        "        self.global_mean = None\n",
        "        self._feature_importances = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Build the decision tree from (X, y).\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.global_mean = np.mean(y)\n",
        "        self.leaf_nodes = []\n",
        "        self._feature_importances = np.zeros(X.shape[1])\n",
        "        self.root = self._build_tree(X, y, depth=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict targets for X. If variant in ['P','CP'], apply P-JS shrinkage post-construction.\n",
        "        \"\"\"\n",
        "        if self.variant in ['P', 'CP']:\n",
        "            self._apply_js_estimator_p()\n",
        "\n",
        "        preds = np.array([self._predict_sample(x, self.root) for x in X])\n",
        "        return preds\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        \"\"\"\n",
        "        Recursively build the tree. If variant in ['C','CP'], apply scaled JS in the splitting stage.\n",
        "        \"\"\"\n",
        "        node = self.Node(depth=depth, max_depth=self.max_depth)\n",
        "        node.n_samples = X.shape[0]\n",
        "        node.prediction = np.mean(y)\n",
        "        node.variance = np.var(y, ddof=1) if X.shape[0] > 1 else 0.0\n",
        "\n",
        "        sse_parent = np.sum((y - node.prediction) ** 2)\n",
        "\n",
        "        # Stopping conditions\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or (X.shape[0] < self.min_samples_split):\n",
        "            self.leaf_nodes.append(node)\n",
        "            return node\n",
        "\n",
        "        best_mse = float('inf')\n",
        "        best_feat, best_thresh = None, None\n",
        "        best_imp_dec = 0.0\n",
        "\n",
        "        m_temp = len(self.leaf_nodes)\n",
        "\n",
        "        for feat_index in range(X.shape[1]):\n",
        "            thresholds = np.unique(X[:, feat_index])\n",
        "            for thresh in thresholds:\n",
        "                left_indices = X[:, feat_index] <= thresh\n",
        "                right_indices = X[:, feat_index] > thresh\n",
        "                if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
        "                    continue\n",
        "                y_left, y_right = y[left_indices], y[right_indices]\n",
        "\n",
        "                if self.variant in ['C','CP'] and m_temp >= 3:\n",
        "                    # Scaled JS if enough leaves\n",
        "                    c1_pred = np.mean(y_left)\n",
        "                    c2_pred = np.mean(y_right)\n",
        "                    c1_var = np.var(y_left, ddof=1) if y_left.shape[0] > 1 else 0.0\n",
        "                    c2_var = np.var(y_right, ddof=1) if y_right.shape[0] > 1 else 0.0\n",
        "\n",
        "                    # simulate adding two new leaves in place of current node\n",
        "                    sim_leafs = [leaf for leaf in self.leaf_nodes if leaf != node]\n",
        "                    new_node1 = self.Node()\n",
        "                    new_node1.prediction = c1_pred\n",
        "                    new_node1.variance = c1_var\n",
        "                    new_node2 = self.Node()\n",
        "                    new_node2.prediction = c2_pred\n",
        "                    new_node2.variance = c2_var\n",
        "                    sim_leafs += [new_node1, new_node2]\n",
        "\n",
        "                    GM = np.mean([leaf.prediction for leaf in sim_leafs])\n",
        "                    sum_n_mu_diff_sq = 0.0\n",
        "                    for lf in sim_leafs:\n",
        "                        if lf.variance > 0:\n",
        "                            sum_n_mu_diff_sq += (lf.n_samples / lf.variance) * (lf.prediction - GM) ** 2\n",
        "                    gamma = ((m_temp+1) - 3)/sum_n_mu_diff_sq if sum_n_mu_diff_sq!=0 else 0\n",
        "                    shrink_factor = max(0, 1 - self.lambda_param*gamma)\n",
        "\n",
        "                    c1_js = GM + shrink_factor*(c1_pred - GM)\n",
        "                    c2_js = GM + shrink_factor*(c2_pred - GM)\n",
        "\n",
        "                    mse_left = np.sum((y_left - c1_js)**2)\n",
        "                    mse_right = np.sum((y_right - c2_js)**2)\n",
        "                    mse = mse_left + mse_right\n",
        "                else:\n",
        "                    # Traditional SSE\n",
        "                    left_mean = np.mean(y_left)\n",
        "                    right_mean = np.mean(y_right)\n",
        "                    mse_left = np.sum((y_left - left_mean)**2)\n",
        "                    mse_right = np.sum((y_right - right_mean)**2)\n",
        "                    mse = mse_left + mse_right\n",
        "\n",
        "                imp_dec = sse_parent - mse\n",
        "                if mse< best_mse:\n",
        "                    best_mse = mse\n",
        "                    best_feat = feat_index\n",
        "                    best_thresh = thresh\n",
        "                    best_imp_dec = imp_dec\n",
        "\n",
        "        if best_feat is not None:\n",
        "            node.feature_index = best_feat\n",
        "            node.threshold = best_thresh\n",
        "            self._feature_importances[best_feat] += best_imp_dec\n",
        "\n",
        "            left_indices = X[:, best_feat] <= best_thresh\n",
        "            right_indices = X[:, best_feat] > best_thresh\n",
        "            X_left, y_left = X[left_indices], y[left_indices]\n",
        "            X_right, y_right = X[right_indices], y[right_indices]\n",
        "            node.left = self._build_tree(X_left, y_left, depth+1)\n",
        "            node.right = self._build_tree(X_right, y_right, depth+1)\n",
        "        else:\n",
        "            self.leaf_nodes.append(node)\n",
        "\n",
        "        return node\n",
        "\n",
        "    def _apply_js_estimator_p(self):\n",
        "        \"\"\"\n",
        "        James-Stein shrinkage in the prediction stage.\n",
        "        \"\"\"\n",
        "        from collections import deque\n",
        "        self.leaf_nodes = []\n",
        "        queue = deque([self.root])\n",
        "        while queue:\n",
        "            nd = queue.popleft()\n",
        "            if nd.left is None and nd.right is None:\n",
        "                self.leaf_nodes.append(nd)\n",
        "            else:\n",
        "                if nd.left: queue.append(nd.left)\n",
        "                if nd.right: queue.append(nd.right)\n",
        "\n",
        "        m = len(self.leaf_nodes)\n",
        "        if m<=3:\n",
        "            return\n",
        "\n",
        "        preds = np.array([ln.prediction for ln in self.leaf_nodes])\n",
        "        GM = np.mean(preds)\n",
        "\n",
        "        denominator = 0.0\n",
        "        for ln in self.leaf_nodes:\n",
        "            if ln.variance>0:\n",
        "                denominator += (ln.n_samples/ln.variance)*((ln.prediction - GM)**2)\n",
        "\n",
        "        gamma = (m-3)/denominator if denominator!=0 else 0\n",
        "        shrink_factor = max(0,1-gamma)\n",
        "\n",
        "        for ln in self.leaf_nodes:\n",
        "            ln.prediction = GM + shrink_factor*(ln.prediction - GM)\n",
        "\n",
        "    def _predict_sample(self, x, node):\n",
        "        if node.left is None and node.right is None:\n",
        "            return node.prediction\n",
        "        if x[node.feature_index]<= node.threshold:\n",
        "            return self._predict_sample(x, node.left)\n",
        "        else:\n",
        "            return self._predict_sample(x, node.right)\n",
        "\n",
        "    @property\n",
        "    def feature_importances_(self):\n",
        "        \"\"\"\n",
        "        Normalized feature importances based on sum of SSE reduction.\n",
        "        \"\"\"\n",
        "        if self._feature_importances is None:\n",
        "            return None\n",
        "        total = self._feature_importances.sum()\n",
        "        if total>0:\n",
        "            return self._feature_importances/total\n",
        "        else:\n",
        "            return self._feature_importances\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\"\n",
        "        Return parameters for this estimator to facilitate hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'variant': self.variant,\n",
        "            'max_depth': self.max_depth,\n",
        "            'min_samples_split': self.min_samples_split,\n",
        "            'lambda_param': self.lambda_param\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        \"\"\"\n",
        "        Set the parameters of this estimator.\n",
        "        \"\"\"\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self"
      ],
      "metadata": {
        "id": "hScLtBu5jkNb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSRF"
      ],
      "metadata": {
        "id": "MVOJyawXjq2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JamesSteinRandomForestRegressor:\n",
        "    \"\"\"\n",
        "    James-Stein Random Forest Regressor (JSRFR).\n",
        "\n",
        "    Builds an ensemble of JamesSteinDecisionTreeRegressor trees in parallel.\n",
        "    Supports 'P', 'C', 'CP' variants. Aggregates feature importances.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_estimators=100,\n",
        "                 variant='CP',\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 lambda_param=1.0,\n",
        "                 max_features='sqrt',\n",
        "                 random_state=None):\n",
        "        if variant not in ['P','C','CP']:\n",
        "            raise ValueError(\"variant must be 'P','C', or 'CP'.\")\n",
        "        self.n_estimators = n_estimators\n",
        "        self.variant = variant\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.lambda_param = lambda_param\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.trees = []\n",
        "        self.n_features_ = None\n",
        "        self.max_features_ = None\n",
        "        self._aggregate_importances = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Build an ensemble of JamesSteinDecisionTreeRegressor from (X,y).\n",
        "        Uses bootstrap sampling + parallel building.\n",
        "        \"\"\"\n",
        "        self.n_features_ = X.shape[1]\n",
        "        self.max_features_ = self._determine_max_features(X.shape[1])\n",
        "\n",
        "        if self.random_state is not None:\n",
        "            import numpy as np\n",
        "            rng = np.random.RandomState(self.random_state)\n",
        "            tree_states = rng.randint(0, np.iinfo(np.int32).max, size=self.n_estimators)\n",
        "        else:\n",
        "            tree_states = [None]*self.n_estimators\n",
        "\n",
        "        def build_single_tree(i):\n",
        "            rng = np.random.RandomState(tree_states[i])\n",
        "            indices = rng.choice(X.shape[0], X.shape[0], replace=True)\n",
        "            X_samp, y_samp = X[indices], y[indices]\n",
        "            dtree = JamesSteinDecisionTreeRegressor(\n",
        "                variant=self.variant,\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                lambda_param=self.lambda_param\n",
        "            )\n",
        "            dtree.fit(X_samp, y_samp)\n",
        "            return dtree\n",
        "\n",
        "        from joblib import Parallel, delayed\n",
        "        self.trees = Parallel(n_jobs=2, backend='loky')(\n",
        "            delayed(build_single_tree)(i) for i in range(self.n_estimators)\n",
        "        )\n",
        "\n",
        "        self._aggregate_feature_importances()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict by averaging predictions from all trees in parallel.\n",
        "        \"\"\"\n",
        "        from joblib import Parallel, delayed\n",
        "        all_preds = Parallel(n_jobs=2, backend='loky')(\n",
        "            delayed(tree.predict)(X) for tree in self.trees\n",
        "        )\n",
        "        all_preds = np.array(all_preds)\n",
        "        return np.mean(all_preds, axis=0)\n",
        "\n",
        "    def _determine_max_features(self, n_features):\n",
        "        if isinstance(self.max_features,int):\n",
        "            return self.max_features\n",
        "        elif isinstance(self.max_features,float):\n",
        "            return max(1, int(self.max_features*n_features))\n",
        "        elif isinstance(self.max_features,str):\n",
        "            if self.max_features=='sqrt':\n",
        "                return max(1, int(np.sqrt(n_features)))\n",
        "            elif self.max_features=='log2':\n",
        "                return max(1, int(np.log2(n_features)))\n",
        "            else:\n",
        "                raise ValueError(\"Invalid value for max_features.\")\n",
        "        elif self.max_features is None:\n",
        "            return n_features\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for max_features.\")\n",
        "\n",
        "    def _aggregate_feature_importances(self):\n",
        "        \"\"\"\n",
        "        Sum up each tree's feature importances. Normalization occurs in the property.\n",
        "        \"\"\"\n",
        "        self._aggregate_importances = np.zeros(self.n_features_)\n",
        "        for tr in self.trees:\n",
        "            fi = tr.feature_importances_\n",
        "            if fi is not None:\n",
        "                self._aggregate_importances += fi\n",
        "\n",
        "    @property\n",
        "    def feature_importances_(self):\n",
        "        \"\"\"\n",
        "        Normalized feature importances across entire forest.\n",
        "        \"\"\"\n",
        "        if self._aggregate_importances is None:\n",
        "            return None\n",
        "        total = self._aggregate_importances.sum()\n",
        "        if total>0:\n",
        "            return self._aggregate_importances/total\n",
        "        else:\n",
        "            return self._aggregate_importances\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\"\n",
        "        Return parameters for this estimator to facilitate hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'n_estimators': self.n_estimators,\n",
        "            'variant': self.variant,\n",
        "            'max_depth': self.max_depth,\n",
        "            'min_samples_split': self.min_samples_split,\n",
        "            'lambda_param': self.lambda_param,\n",
        "            'max_features': self.max_features,\n",
        "            'random_state': self.random_state\n",
        "        }\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        \"\"\"\n",
        "        Set the parameters of this estimator.\n",
        "        \"\"\"\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self"
      ],
      "metadata": {
        "id": "4xWYKm-mjqz1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "K0Y08rMahrGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_concrete_data():\n",
        "    \"\"\"\n",
        "    Load the Concrete Compressive Strength dataset from UCI.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    X : ndarray (n_samples, 8)\n",
        "    y : ndarray (n_samples,)\n",
        "    \"\"\"\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
        "    resp = requests.get(url)\n",
        "    import pandas as pd\n",
        "    data_xls = pd.read_excel(BytesIO(resp.content))\n",
        "    df = data_xls.copy()\n",
        "\n",
        "    X = df.iloc[:, :-1].values\n",
        "    y = df.iloc[:, -1].values\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "NrQmV8Z5jyJW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_abalone_data():\n",
        "    \"\"\"\n",
        "    Load the Abalone dataset from OpenML.\n",
        "    Check for the correct target column name.\n",
        "    If 'Rings' is not present, attempt alternative columns.\n",
        "    \"\"\"\n",
        "    from sklearn.datasets import fetch_openml\n",
        "    abalone = fetch_openml(name='abalone', version=1, as_frame=True)\n",
        "    df = abalone.frame.copy()\n",
        "\n",
        "    # Inspect columns to handle variations in target naming\n",
        "    cols = df.columns.tolist()\n",
        "    # Potential abalone target columns: 'Rings', 'Class_number_of_rings', etc.\n",
        "    possible_targets = ['Rings', 'Class_number_of_rings', 'rings']\n",
        "\n",
        "    target_col = None\n",
        "    for tgt in possible_targets:\n",
        "        if tgt in cols:\n",
        "            target_col = tgt\n",
        "            break\n",
        "    if target_col is None:\n",
        "        raise ValueError(f\"Could not find a 'Rings' or alternative in columns: {cols}\")\n",
        "\n",
        "    # Drop the found target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col].astype(float).values\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "EAybEE6rjyGw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "jvammcxlj4lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_abalone(X_df):\n",
        "    \"\"\"\n",
        "    One-Hot encode 'Sex' and keep numeric columns as is.\n",
        "    \"\"\"\n",
        "    cat_cols = ['Sex']\n",
        "    numeric_cols = [c for c in X_df.columns if c not in cat_cols]\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        [('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "    X_transf = preprocessor.fit_transform(X_df)\n",
        "    cat_feat_names = preprocessor.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
        "    feat_names = list(cat_feat_names)+numeric_cols\n",
        "    return X_transf, feat_names"
      ],
      "metadata": {
        "id": "KdSP7MUdj4bt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nested CV"
      ],
      "metadata": {
        "id": "mRwM0vBgj7ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nested_cv_random_search(model_class, param_distributions, X, y,\n",
        "                            n_outer=3, n_iter=3, random_state=42):\n",
        "    \"\"\"\n",
        "    Perform Nested Cross Validation with an outer KFold for final RMSE estimate\n",
        "    and an inner RandomizedSearchCV for hyperparameter tuning.\n",
        "    Compute RMSE by sqrt of MSE in the outer loop.\n",
        "\n",
        "    model_class: e.g. JamesSteinRandomForestRegressor\n",
        "    param_distributions: for RandomizedSearchCV\n",
        "    X, y: data\n",
        "    n_outer: outer folds\n",
        "    n_iter: # param combos in random search\n",
        "    random_state: seed\n",
        "    \"\"\"\n",
        "    from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "\n",
        "    outer_cv = KFold(n_splits=n_outer, shuffle=True, random_state=random_state)\n",
        "    outer_scores = []\n",
        "    outer_fi_list = []\n",
        "    best_params_list = []\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(X,y):\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Inner CV for param tuning\n",
        "        inner_cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=model_class(),\n",
        "            param_distributions=param_distributions,\n",
        "            n_iter=n_iter,\n",
        "            cv=inner_cv,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=1,\n",
        "            random_state=random_state\n",
        "        )\n",
        "        search.fit(X_train, y_train)\n",
        "        best_model = search.best_estimator_\n",
        "        best_params_list.append(search.best_params_)\n",
        "\n",
        "        # Evaluate outer fold performance via RMSE\n",
        "        y_pred = best_model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        outer_scores.append(rmse)\n",
        "\n",
        "        # If feature_importances_ is available, store it\n",
        "        fi = None\n",
        "        if hasattr(best_model, 'feature_importances_'):\n",
        "            fi = best_model.feature_importances_\n",
        "        outer_fi_list.append(fi)\n",
        "\n",
        "    return outer_scores, outer_fi_list, best_params_list"
      ],
      "metadata": {
        "id": "9e6Is5k_j7h5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "-7xjN8FJkDLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rmse_dataframe(results, model_names, ds_names):\n",
        "    \"\"\"\n",
        "    Create a DataFrame of cross-validated RMSE from the 'results' dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    results : dict\n",
        "        Contains nested-cv scores and info for each model and dataset.\n",
        "    model_names : list of str\n",
        "        The keys used for models in results.\n",
        "    ds_names : list of str\n",
        "        The dataset names used in results.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    rmse_df : pd.DataFrame\n",
        "        DataFrame of mean RMSE, indexed by Model, columns by dataset.\n",
        "    \"\"\"\n",
        "    data_for_df = []\n",
        "    for m in model_names:\n",
        "        row = {}\n",
        "        row['Model'] = m\n",
        "        for ds in ds_names:\n",
        "            cv_scores = results[m][ds]['scores']\n",
        "            mean_rmse = np.mean(cv_scores)\n",
        "            row[ds] = mean_rmse\n",
        "        data_for_df.append(row)\n",
        "    rmse_df = pd.DataFrame(data_for_df)\n",
        "    rmse_df.set_index(\"Model\", inplace=True)\n",
        "    return rmse_df"
      ],
      "metadata": {
        "id": "p3QyONZ7kFyp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_rmse_bar_chart(rmse_df):\n",
        "    \"\"\"\n",
        "    Plot a grouped bar chart of cross-validated RMSE across datasets.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    rmse_df : pd.DataFrame\n",
        "        DataFrame with mean RMSE per model (index) and per dataset (columns).\n",
        "    \"\"\"\n",
        "    ds_names = rmse_df.columns\n",
        "    model_names = rmse_df.index\n",
        "    x = np.arange(len(ds_names))\n",
        "    width = 0.2\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    for i, model_name in enumerate(model_names):\n",
        "        bar_vals = [rmse_df.loc[model_name, ds] for ds in ds_names]\n",
        "        ax.bar(x + (i - (len(model_names)-1)/2)*width,\n",
        "               bar_vals, width, label=model_name)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(ds_names)\n",
        "    ax.set_ylabel(\"Mean RMSE (Nested CV)\")\n",
        "    ax.set_title(\"Cross-Validated RMSE Performance\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wzZWUEeykFwE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importances_subplots(results, model_names, ds_names):\n",
        "    \"\"\"\n",
        "    Plot twelve horizontal bar plots (subplots) for each model's cross-validated feature importances across all datasets.\n",
        "    Organized as models on columns and datasets on rows.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    results : dict\n",
        "        Contains nested-cv scores and info for each model and dataset.\n",
        "    model_names : list of str\n",
        "        The keys used for models in results.\n",
        "    ds_names : list of str\n",
        "        The dataset names used in results.\n",
        "    \"\"\"\n",
        "    num_models = len(model_names)\n",
        "    num_datasets = len(ds_names)\n",
        "    fig, axs = plt.subplots(num_datasets, num_models, figsize=(5*num_models, 4*num_datasets))\n",
        "\n",
        "    if num_datasets ==1 and num_models==1:\n",
        "        axs = np.array([[axs]])\n",
        "    elif num_datasets ==1 or num_models ==1:\n",
        "        axs = axs.reshape(num_datasets, num_models)\n",
        "\n",
        "    for row_idx, ds in enumerate(ds_names):\n",
        "        for col_idx, model in enumerate(model_names):\n",
        "            fi_arrays = results[model][ds]['fi_list']\n",
        "            feats = results[model][ds]['features']\n",
        "            valid_fi = [f for f in fi_arrays if f is not None]\n",
        "            ax = axs[row_idx, col_idx]\n",
        "            if len(valid_fi)==0:\n",
        "                ax.barh([0],[0])\n",
        "                ax.set_title(f\"{model} on {ds} (No FI)\")\n",
        "                continue\n",
        "            avg_fi = np.mean(valid_fi, axis=0)\n",
        "            sorted_idx = np.argsort(avg_fi)\n",
        "            sorted_fi = avg_fi[sorted_idx]\n",
        "            sorted_feats = [feats[idx] for idx in sorted_idx]\n",
        "            ax.barh(sorted_feats, sorted_fi)\n",
        "            ax.set_title(f\"{model} on {ds}\\nFeature Importances\")\n",
        "            ax.set_xlabel(\"Avg Feature Importance\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ecLPIjyDRlZW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "wl1XNZmEkLBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main workflow to:\n",
        "    1) Load 3 datasets (Diabetes, Concrete, Abalone).\n",
        "    2) Evaluate P-JSRFR, C-JSRFR, CP-JSRFR, and scikit-learn RandomForest via nested CV (RMSE).\n",
        "    3) Compare cross-validated RMSE and feature importances.\n",
        "    4) Display results in a DataFrame, a grouped bar chart, and horizontal bar subplots for feature importances.\n",
        "    \"\"\"\n",
        "    print(\"Loading three datasets...\\n\")\n",
        "\n",
        "    # 1) Diabetes\n",
        "    diabetes = load_diabetes()\n",
        "    X_diab, y_diab = diabetes.data, diabetes.target\n",
        "    feat_diab = diabetes.feature_names\n",
        "    print(\"Diabetes dataset loaded.\")\n",
        "\n",
        "    # 2) Concrete\n",
        "    X_conc, y_conc = load_concrete_data()\n",
        "    feat_conc = [\"Cement\", \"Slag\", \"FlyAsh\", \"Water\", \"SP\", \"CoarseAggr\", \"FineAggr\", \"Age\"]\n",
        "    print(\"Concrete dataset loaded.\")\n",
        "\n",
        "    # 3) Abalone\n",
        "    X_ab_df, y_aba = load_abalone_data()\n",
        "    X_aba, feat_aba = preprocess_abalone(X_ab_df)\n",
        "    print(\"Abalone dataset loaded.\\n\")\n",
        "\n",
        "    # Prepare dictionary for iteration\n",
        "    datasets = {\n",
        "        \"Diabetes\": (X_diab, y_diab, feat_diab),\n",
        "        \"Concrete\": (X_conc, y_conc, feat_conc),\n",
        "        \"Abalone\":  (X_aba,  y_aba,  feat_aba)\n",
        "    }\n",
        "\n",
        "    # Param distributions for JamesSteinRandomForestRegressor\n",
        "    from sklearn.ensemble import RandomForestRegressor as SKRF\n",
        "    param_dist_jsrfr = {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [5, 10, None],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'lambda_param': [0.5, 1.0, 2.0],\n",
        "        'variant': ['P', 'C', 'CP'],\n",
        "        'max_features': ['sqrt', 0.5]\n",
        "    }\n",
        "\n",
        "    # Param distributions for scikit-learn RandomForestRegressor\n",
        "    param_dist_rf = {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [5, 10, None],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'max_features': ['sqrt', 0.5]\n",
        "    }\n",
        "\n",
        "    # Define 4 models: P-JSRFR, C-JSRFR, CP-JSRFR, SklearnRF\n",
        "    # Store results in a dictionary\n",
        "    results = {\n",
        "        \"P-JSRFR\": {},\n",
        "        \"C-JSRFR\": {},\n",
        "        \"CP-JSRFR\": {},\n",
        "        \"SklearnRF\": {}\n",
        "    }\n",
        "\n",
        "    # Do a small nested CV: 3 outer folds, 3 param combos in the inner loop\n",
        "    n_outer = 3\n",
        "    n_iter = 3\n",
        "    random_state = 42\n",
        "\n",
        "    from sklearn.ensemble import RandomForestRegressor as SKRF\n",
        "\n",
        "    # Evaluate each dataset across the 4 model settings\n",
        "    print(\"Running models...\\n\")\n",
        "    for dname, (X_data, y_data, feats) in datasets.items():\n",
        "        print(f\"=== Dataset: {dname} ===\\n\")\n",
        "\n",
        "        # 1) P-JSRFR\n",
        "        param_dist_p = dict(param_dist_jsrfr)\n",
        "        param_dist_p['variant'] = ['P']\n",
        "        p_scores, p_fi_list, p_best_params = nested_cv_random_search(\n",
        "            model_class=lambda: JamesSteinRandomForestRegressor(random_state=42),\n",
        "            param_distributions=param_dist_p,\n",
        "            X=X_data, y=y_data,\n",
        "            n_outer=n_outer, n_iter=n_iter,\n",
        "            random_state=random_state\n",
        "        )\n",
        "        results[\"P-JSRFR\"][dname] = {\n",
        "            \"scores\": p_scores,\n",
        "            \"fi_list\": p_fi_list,\n",
        "            \"best_params\": p_best_params,\n",
        "            \"features\": feats\n",
        "        }\n",
        "        print(f\"P-JSRFR completed for {dname}.\")\n",
        "\n",
        "        # 2) C-JSRFR\n",
        "        param_dist_c = dict(param_dist_jsrfr)\n",
        "        param_dist_c['variant'] = ['C']\n",
        "        c_scores, c_fi_list, c_best_params = nested_cv_random_search(\n",
        "            model_class=lambda: JamesSteinRandomForestRegressor(random_state=42),\n",
        "            param_distributions=param_dist_c,\n",
        "            X=X_data, y=y_data,\n",
        "            n_outer=n_outer, n_iter=n_iter,\n",
        "            random_state=random_state\n",
        "        )\n",
        "        results[\"C-JSRFR\"][dname] = {\n",
        "            \"scores\": c_scores,\n",
        "            \"fi_list\": c_fi_list,\n",
        "            \"best_params\": c_best_params,\n",
        "            \"features\": feats\n",
        "        }\n",
        "        print(f\"C-JSRFR completed for {dname}.\")\n",
        "\n",
        "        # 3) CP-JSRFR\n",
        "        param_dist_cp = dict(param_dist_jsrfr)\n",
        "        param_dist_cp['variant'] = ['CP']\n",
        "        cp_scores, cp_fi_list, cp_best_params = nested_cv_random_search(\n",
        "            model_class=lambda: JamesSteinRandomForestRegressor(random_state=42),\n",
        "            param_distributions=param_dist_cp,\n",
        "            X=X_data, y=y_data,\n",
        "            n_outer=n_outer, n_iter=n_iter,\n",
        "            random_state=random_state\n",
        "        )\n",
        "        results[\"CP-JSRFR\"][dname] = {\n",
        "            \"scores\": cp_scores,\n",
        "            \"fi_list\": cp_fi_list,\n",
        "            \"best_params\": cp_best_params,\n",
        "            \"features\": feats\n",
        "        }\n",
        "        print(f\"CP-JSRFR completed for {dname}.\")\n",
        "\n",
        "        # 4) scikit-learn RF\n",
        "        param_dist_skrf = dict(param_dist_rf)\n",
        "        rf_scores, rf_fi_list, rf_best_params = nested_cv_random_search(\n",
        "            model_class=lambda: SKRF(random_state=42),\n",
        "            param_distributions=param_dist_skrf,\n",
        "            X=X_data, y=y_data,\n",
        "            n_outer=n_outer, n_iter=n_iter,\n",
        "            random_state=random_state\n",
        "        )\n",
        "        results[\"SklearnRF\"][dname] = {\n",
        "            \"scores\": rf_scores,\n",
        "            \"fi_list\": rf_fi_list,\n",
        "            \"best_params\": rf_best_params,\n",
        "            \"features\": feats\n",
        "        }\n",
        "        print(f\"Sklearn RF completed for {dname}.\\n\")\n",
        "\n",
        "    # Summarize cross-validated RMSE in a DataFrame\n",
        "    print(\"Summarizing results...\\n\")\n",
        "    model_names = [\"P-JSRFR\", \"C-JSRFR\", \"CP-JSRFR\", \"SklearnRF\"]\n",
        "    ds_names = list(datasets.keys())\n",
        "    rmse_df = create_rmse_dataframe(results, model_names, ds_names)\n",
        "\n",
        "    print(\"\\n=== Cross-validated RMSE DataFrame ===\")\n",
        "    display(rmse_df)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Plot a grouped bar chart of RMSE across datasets\n",
        "    plot_rmse_bar_chart(rmse_df)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # # Horizontal bar plots of cross-validated feature importances\n",
        "    # plot_feature_importances_subplots(results, model_names, ds_names)"
      ],
      "metadata": {
        "id": "6z9-IBlXhrEi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5mevenTanNTU",
        "outputId": "eccd38fe-13bb-4dfe-e60c-18dcf261afa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading three datasets...\n",
            "\n",
            "Diabetes dataset loaded.\n",
            "Concrete dataset loaded.\n",
            "Abalone dataset loaded.\n",
            "\n",
            "Running models...\n",
            "\n",
            "=== Dataset: Diabetes ===\n",
            "\n",
            "P-JSRFR completed for Diabetes.\n",
            "C-JSRFR completed for Diabetes.\n",
            "CP-JSRFR completed for Diabetes.\n",
            "Sklearn RF completed for Diabetes.\n",
            "\n",
            "=== Dataset: Concrete ===\n",
            "\n",
            "P-JSRFR completed for Concrete.\n",
            "C-JSRFR completed for Concrete.\n",
            "CP-JSRFR completed for Concrete.\n",
            "Sklearn RF completed for Concrete.\n",
            "\n",
            "=== Dataset: Abalone ===\n",
            "\n",
            "P-JSRFR completed for Abalone.\n",
            "C-JSRFR completed for Abalone.\n",
            "CP-JSRFR completed for Abalone.\n",
            "Sklearn RF completed for Abalone.\n",
            "\n",
            "Summarizing results...\n",
            "\n",
            "\n",
            "=== Cross-validated RMSE DataFrame ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Diabetes  Concrete   Abalone\n",
              "Model                                   \n",
              "P-JSRFR    57.989245  5.397148  2.191960\n",
              "C-JSRFR    58.042868  5.398182  2.192315\n",
              "CP-JSRFR   58.048023  5.398182  2.191497\n",
              "SklearnRF  57.080455  5.580644  2.182215"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-338bc9da-7316-4364-9e1d-9b1078ec283c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>Concrete</th>\n",
              "      <th>Abalone</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P-JSRFR</th>\n",
              "      <td>57.989245</td>\n",
              "      <td>5.397148</td>\n",
              "      <td>2.191960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C-JSRFR</th>\n",
              "      <td>58.042868</td>\n",
              "      <td>5.398182</td>\n",
              "      <td>2.192315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CP-JSRFR</th>\n",
              "      <td>58.048023</td>\n",
              "      <td>5.398182</td>\n",
              "      <td>2.191497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SklearnRF</th>\n",
              "      <td>57.080455</td>\n",
              "      <td>5.580644</td>\n",
              "      <td>2.182215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-338bc9da-7316-4364-9e1d-9b1078ec283c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-338bc9da-7316-4364-9e1d-9b1078ec283c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-338bc9da-7316-4364-9e1d-9b1078ec283c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-27b0835a-5718-4866-82bd-0dc618b9a10f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27b0835a-5718-4866-82bd-0dc618b9a10f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-27b0835a-5718-4866-82bd-0dc618b9a10f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    main()\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"C-JSRFR\",\n          \"SklearnRF\",\n          \"P-JSRFR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4738743183918942,\n        \"min\": 57.08045488497234,\n        \"max\": 58.04802264449699,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          58.04286788501246,\n          57.08045488497234,\n          57.98924500857106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Concrete\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09140471435122537,\n        \"min\": 5.397147558176126,\n        \"max\": 5.580644040848335,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5.398182041610036,\n          5.580644040848335,\n          5.397147558176126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abalone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004865820712567875,\n        \"min\": 2.1822153953057986,\n        \"max\": 2.1923150276782226,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.1923150276782226,\n          2.1822153953057986,\n          2.1919600908222394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
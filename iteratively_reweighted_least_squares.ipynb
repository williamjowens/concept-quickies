{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IRLS Class"
      ],
      "metadata": {
        "id": "oeGmVAx5oJTa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e4dyU8G9mDsZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import norm\n",
        "from scipy.special import gammaln, digamma, polygamma\n",
        "\n",
        "class IRLSRegression:\n",
        "    def __init__(self, family='linear', link='identity', inverse_link=None,\n",
        "                 regularization='none', reg_lambda=1.0, reg_alpha=0.5,\n",
        "                 l1_method='coordinate_descent', tol=1e-6, max_iter=100,\n",
        "                 max_cd_iter=100, cd_tol=1e-4, verbose=False,\n",
        "                 scale=False, scaling_method='standardization',\n",
        "                 encode_categorical=False, categorical_features=None,\n",
        "                 categorical_encoding=None, ordinal_mapping=None):\n",
        "\n",
        "        self.family = family.lower()\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.verbose = verbose\n",
        "        self.beta_ = None\n",
        "\n",
        "        # Initialize alpha if needed\n",
        "        if self.family in ['negative_binomial', 'gamma']:\n",
        "            self.alpha_ = 1.0\n",
        "        else:\n",
        "            self.alpha_ = None\n",
        "\n",
        "        # Regularization checks\n",
        "        self.regularization = regularization.lower()\n",
        "        if self.regularization not in ['none','l1','l2','elasticnet']:\n",
        "            raise ValueError(\"Invalid regularization.\")\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.reg_alpha = reg_alpha\n",
        "\n",
        "        self.l1_method = l1_method.lower()\n",
        "        if self.l1_method not in ['soft_thresholding','coordinate_descent']:\n",
        "            raise ValueError(\"l1_method must be 'soft_thresholding' or 'coordinate_descent'\")\n",
        "\n",
        "        self.max_cd_iter = max_cd_iter\n",
        "        self.cd_tol = cd_tol\n",
        "\n",
        "        self.scale = scale\n",
        "        self.scaling_method = scaling_method.lower()\n",
        "        if self.scaling_method not in ['standardization','minmax']:\n",
        "            raise ValueError(\"scaling_method must be 'standardization' or 'minmax'\")\n",
        "\n",
        "        self.encode_categorical = encode_categorical\n",
        "        self.categorical_features = categorical_features\n",
        "        self.categorical_encoding = categorical_encoding\n",
        "        self.ordinal_mapping = ordinal_mapping\n",
        "\n",
        "        if self.encode_categorical:\n",
        "            if not self.categorical_features:\n",
        "                raise ValueError(\"Must provide categorical_features.\")\n",
        "            if not self.categorical_encoding:\n",
        "                raise ValueError(\"Must provide categorical_encoding.\")\n",
        "            for f in self.categorical_features:\n",
        "                if f not in self.categorical_encoding:\n",
        "                    raise ValueError(f\"No encoding for {f}.\")\n",
        "                if self.categorical_encoding[f] not in ['nominal','ordinal']:\n",
        "                    raise ValueError(f\"Invalid encoding for {f}.\")\n",
        "            ordinal_feats=[f for f in self.categorical_features if self.categorical_encoding[f]=='ordinal']\n",
        "            if ordinal_feats and not self.ordinal_mapping:\n",
        "                raise ValueError(\"Must provide ordinal_mapping for ordinal features.\")\n",
        "            for f in ordinal_feats:\n",
        "                if f not in self.ordinal_mapping:\n",
        "                    raise ValueError(f\"No mapping for {f}.\")\n",
        "\n",
        "        # Define supported links\n",
        "        self.supported_links = {\n",
        "            'linear': {\n",
        "                'identity': (self.identity, self.identity),\n",
        "            },\n",
        "            'logistic': {\n",
        "                'logit': (self.logit, self.sigmoid),\n",
        "                'probit': (self.probit, self.probit_inverse),\n",
        "            },\n",
        "            'poisson': {\n",
        "                'log': (self.log, self.exp),\n",
        "                'identity': (self.identity, self.identity),\n",
        "            },\n",
        "            'negative_binomial': {\n",
        "                'log': (self.log, self.exp),\n",
        "            },\n",
        "            'gamma': {\n",
        "                'inverse': (self.inverse_link_gamma, self.inverse_link_gamma_inv),\n",
        "                'log': (self.log, self.exp),\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Assign link and inverse link\n",
        "        if isinstance(link, str):\n",
        "            if self.family not in self.supported_links:\n",
        "                raise ValueError(f\"Unsupported family '{self.family}'\")\n",
        "            if link in self.supported_links[self.family]:\n",
        "                self.link_func, self.inv_link_func = self.supported_links[self.family][link]\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported link '{link}' for '{self.family}'.\")\n",
        "        elif callable(link):\n",
        "            if inverse_link is None or not callable(inverse_link):\n",
        "                raise ValueError(\"Must provide inverse_link if link is callable.\")\n",
        "            self.link_func = link\n",
        "            self.inv_link_func = inverse_link\n",
        "        else:\n",
        "            raise ValueError(\"Invalid link specification.\")\n",
        "\n",
        "        self.dummy_columns = []\n",
        "        self.ordinal_mappings = {}\n",
        "        self.scaler_params_ = {}\n",
        "        self.scaler_features_ = []\n",
        "        self.feature_names_ = []\n",
        "\n",
        "    @staticmethod\n",
        "    def identity(mu):\n",
        "        return mu\n",
        "\n",
        "    @staticmethod\n",
        "    def logit(mu):\n",
        "        mu = np.clip(mu,1e-10,1-1e-10)\n",
        "        return np.log(mu/(1-mu))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(eta):\n",
        "        return 1/(1+np.exp(-eta))\n",
        "\n",
        "    @staticmethod\n",
        "    def probit(mu):\n",
        "        return norm.ppf(mu)\n",
        "\n",
        "    @staticmethod\n",
        "    def probit_inverse(eta):\n",
        "        return norm.cdf(eta)\n",
        "\n",
        "    @staticmethod\n",
        "    def log(mu):\n",
        "        mu = np.clip(mu,1e-10,None)\n",
        "        return np.log(mu)\n",
        "\n",
        "    @staticmethod\n",
        "    def exp(eta):\n",
        "        return np.exp(eta)\n",
        "\n",
        "    @staticmethod\n",
        "    def inverse_link_gamma(mu):\n",
        "        mu=np.clip(mu,1e-10,None)\n",
        "        return 1/mu\n",
        "\n",
        "    @staticmethod\n",
        "    def inverse_link_gamma_inv(eta):\n",
        "        eta=np.clip(eta,1e-10,None)\n",
        "        return 1/eta\n",
        "\n",
        "    def variance(self, mu):\n",
        "        if self.family=='linear':\n",
        "            return 1\n",
        "        elif self.family=='logistic':\n",
        "            return mu*(1-mu)\n",
        "        elif self.family=='poisson':\n",
        "            return mu\n",
        "        elif self.family=='negative_binomial':\n",
        "            return mu+self.alpha_*mu**2\n",
        "        elif self.family=='gamma':\n",
        "            return (mu**2)/self.alpha_\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported family '{self.family}'.\")\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        Xp = self._preprocess_data(X)\n",
        "        beta, alpha = self._initialize_coefficients(Xp, y)\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            eta = self._compute_eta(Xp, beta)\n",
        "            mu = self._compute_mu(eta)\n",
        "            W, z = self._compute_weights_z(mu, y, eta)\n",
        "\n",
        "            beta_new = self._compute_wls_solution(Xp, W, z)\n",
        "\n",
        "            if self.regularization in ['l1','elasticnet']:\n",
        "                beta_new = self._apply_regularization(beta_new, Xp, W, z)\n",
        "\n",
        "            if self.family in ['negative_binomial','gamma']:\n",
        "                alpha_new = self._update_alpha(y, mu)\n",
        "            else:\n",
        "                alpha_new = alpha\n",
        "\n",
        "            converged = self._check_convergence(beta, beta_new, alpha, alpha_new)\n",
        "            beta, alpha = beta_new, alpha_new\n",
        "            self.alpha_ = alpha_new\n",
        "\n",
        "            if converged:\n",
        "                if self.verbose:\n",
        "                    print(f\"Converged in {iteration+1} iterations.\")\n",
        "                break\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"Did not converge within max_iter.\")\n",
        "\n",
        "        self.beta_ = beta\n",
        "        return self\n",
        "\n",
        "    def _preprocess_data(self, X):\n",
        "        if self.encode_categorical:\n",
        "            if not isinstance(X, pd.DataFrame):\n",
        "                raise ValueError(\"X must be DataFrame when encode_categorical=True.\")\n",
        "            X_encoded = self._encode_categorical(X)\n",
        "        else:\n",
        "            if isinstance(X, np.ndarray):\n",
        "                X_encoded = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(X.shape[1])])\n",
        "            elif isinstance(X, pd.DataFrame):\n",
        "                X_encoded = X.copy()\n",
        "            else:\n",
        "                raise ValueError(\"X must be a DataFrame or ndarray.\")\n",
        "\n",
        "        # Cast to float right after encoding to ensure dummies are floats\n",
        "        X_encoded = X_encoded.astype(float)\n",
        "\n",
        "        if self.scale:\n",
        "            Xp,_ = self._scale_features(X_encoded)\n",
        "        else:\n",
        "            Xp = X_encoded.copy()\n",
        "\n",
        "        # Ensure columns are numeric\n",
        "        for col in Xp.columns:\n",
        "            if not np.issubdtype(Xp[col].dtype, np.number):\n",
        "                Xp[col] = pd.to_numeric(Xp[col], errors='coerce').fillna(0.0)\n",
        "\n",
        "        if 'const' not in Xp.columns:\n",
        "            Xp = sm.add_constant(Xp)\n",
        "\n",
        "        # Final cast to float to ensure all columns are float\n",
        "        Xp = Xp.astype(float)\n",
        "        self.feature_names_ = Xp.columns.tolist()\n",
        "        return Xp\n",
        "\n",
        "    def _initialize_coefficients(self, Xp, y):\n",
        "        n_features = Xp.shape[1]\n",
        "        beta = np.zeros(n_features)\n",
        "        alpha = self.alpha_\n",
        "        return beta, alpha\n",
        "\n",
        "    def _compute_eta(self, X, beta):\n",
        "        return X.values @ beta\n",
        "\n",
        "    def _compute_mu(self, eta):\n",
        "        if self.family=='gamma' and self.inv_link_func==self.inverse_link_gamma_inv:\n",
        "            eta = np.clip(eta,1e-10,None)\n",
        "        return self.inv_link_func(eta)\n",
        "\n",
        "    def _compute_weights_z(self, mu, y, eta):\n",
        "        if self.family=='linear':\n",
        "            W = 1.0\n",
        "            z = y\n",
        "        else:\n",
        "            W = self.variance(mu)\n",
        "            W = np.maximum(W,1e-5)\n",
        "            z = eta + (y - mu) / W\n",
        "        return W,z\n",
        "\n",
        "    def _compute_wls_solution(self, X, W, z):\n",
        "        XT_W = X.values.T * W\n",
        "        XTWX = XT_W @ X.values\n",
        "        XTWz = XT_W @ z\n",
        "\n",
        "        if self.regularization in ['l2','elasticnet']:\n",
        "            if 'const' in self.feature_names_:\n",
        "                idx_const = self.feature_names_.index('const')\n",
        "            else:\n",
        "                idx_const = None\n",
        "            penalty_mat = np.eye(XTWX.shape[0])\n",
        "            if idx_const is not None:\n",
        "                penalty_mat[idx_const, idx_const] = 0.0\n",
        "            if self.regularization=='l2':\n",
        "                XTWX += self.reg_lambda * penalty_mat\n",
        "            else:\n",
        "                XTWX += self.reg_lambda * (1-self.reg_alpha) * penalty_mat\n",
        "\n",
        "        try:\n",
        "            beta_new = np.linalg.solve(XTWX, XTWz)\n",
        "        except np.linalg.LinAlgError:\n",
        "            beta_new = np.linalg.lstsq(XTWX, XTWz, rcond=None)[0]\n",
        "        return beta_new\n",
        "\n",
        "    def _apply_regularization(self, beta_new, X, W, z):\n",
        "        if self.regularization=='l1':\n",
        "            lambda_l1 = self.reg_lambda\n",
        "        elif self.regularization=='elasticnet':\n",
        "            lambda_l1 = self.reg_lambda * self.reg_alpha\n",
        "        else:\n",
        "            lambda_l1 = 0.0\n",
        "\n",
        "        if lambda_l1 <= 0:\n",
        "            return beta_new\n",
        "\n",
        "        if self.l1_method=='soft_thresholding':\n",
        "            if 'const' in self.feature_names_:\n",
        "                idx_const = self.feature_names_.index('const')\n",
        "            else:\n",
        "                idx_const = None\n",
        "            for i in range(len(beta_new)):\n",
        "                if i == idx_const:\n",
        "                    continue\n",
        "                val = beta_new[i]\n",
        "                if val > lambda_l1:\n",
        "                    val = val - lambda_l1\n",
        "                elif val < -lambda_l1:\n",
        "                    val = val + lambda_l1\n",
        "                else:\n",
        "                    val = 0.0\n",
        "                beta_new[i]=val\n",
        "        elif self.l1_method=='coordinate_descent':\n",
        "            beta_new = self.coordinate_descent(beta_new.copy(), X.values, W, z, self.reg_lambda, self.reg_alpha)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid l1_method.\")\n",
        "        return beta_new\n",
        "\n",
        "    def _update_alpha(self, y, mu):\n",
        "        if self.family=='negative_binomial':\n",
        "            alpha=self.alpha_\n",
        "            d1=self._neg_binomial_alpha_d1(y, mu, alpha)\n",
        "            eps=1e-6\n",
        "            d1_p=self._neg_binomial_alpha_d1(y, mu, alpha+eps)\n",
        "            d1_m=self._neg_binomial_alpha_d1(y, mu, max(alpha-eps,1e-8))\n",
        "            d2=(d1_p - 2*d1 + d1_m)/(eps**2)\n",
        "            alpha_new=alpha - d1/d2\n",
        "            alpha_new=max(alpha_new,1e-8)\n",
        "            return alpha_new\n",
        "        elif self.family=='gamma':\n",
        "            alpha=self.alpha_\n",
        "            d1,d2=self._gamma_alpha_derivatives(y,mu,alpha)\n",
        "            alpha_new=alpha - d1/d2\n",
        "            alpha_new=max(alpha_new,1e-8)\n",
        "            return alpha_new\n",
        "        else:\n",
        "            return self.alpha_\n",
        "\n",
        "    def _neg_binomial_alpha_d1(self, y, mu, alpha):\n",
        "        y = np.asarray(y)\n",
        "        mu = np.asarray(mu)\n",
        "        a = 1/alpha\n",
        "        yplus = y+a\n",
        "        dig_y_a = digamma(yplus)\n",
        "        dig_a = digamma(a)\n",
        "\n",
        "        term1 = (dig_y_a - dig_a)*(-1/alpha**2)\n",
        "        term2 = (-1/alpha**2)*(-np.log(1+alpha*mu)) + (1/alpha)*(-mu/(1+alpha*mu))\n",
        "        term3 = y*(1/alpha - mu/(1+alpha*mu))\n",
        "\n",
        "        d1_i = term1+term2+term3\n",
        "        return np.sum(d1_i)\n",
        "\n",
        "    def _gamma_alpha_derivatives(self, y, mu, alpha):\n",
        "        y=np.asarray(y)\n",
        "        mu=np.asarray(mu)\n",
        "        d1_i=(np.log(alpha)+1)-digamma(alpha)+np.log(y)-(y/mu)-np.log(mu)\n",
        "        d1=np.sum(d1_i)\n",
        "        n=len(y)\n",
        "        d2 = n*(1/alpha - polygamma(1, alpha))\n",
        "        return d1,d2\n",
        "\n",
        "    def _check_convergence(self, beta, beta_new, alpha, alpha_new):\n",
        "        delta_beta=np.linalg.norm(beta_new - beta)\n",
        "        if self.family in ['negative_binomial','gamma']:\n",
        "            delta_alpha=abs(alpha_new - alpha)\n",
        "            if self.verbose:\n",
        "                print(f\"    ||Δβ||={delta_beta:.6e}, Δα={delta_alpha:.6e}\")\n",
        "            return (delta_beta<self.tol) and (delta_alpha<self.tol)\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(f\"    ||Δβ||={delta_beta:.6e}\")\n",
        "            return (delta_beta<self.tol)\n",
        "\n",
        "    def _encode_categorical(self, X):\n",
        "        X_encoded=X.copy()\n",
        "        for f in self.categorical_features:\n",
        "            etype=self.categorical_encoding[f]\n",
        "            if etype=='nominal':\n",
        "                dummies=pd.get_dummies(X_encoded[f],prefix=f,drop_first=True)\n",
        "                self.dummy_columns.extend(dummies.columns.tolist())\n",
        "                X_encoded=pd.concat([X_encoded,dummies],axis=1)\n",
        "                X_encoded.drop(columns=[f],inplace=True)\n",
        "            elif etype=='ordinal':\n",
        "                mapping={cat:i for i,cat in enumerate(self.ordinal_mapping[f],start=1)}\n",
        "                self.ordinal_mappings[f]=mapping\n",
        "                X_encoded[f]=X_encoded[f].map(mapping)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid encoding.\")\n",
        "        if X_encoded.columns.duplicated().any():\n",
        "            X_encoded = X_encoded.loc[:, ~X_encoded.columns.duplicated()]\n",
        "        return X_encoded\n",
        "\n",
        "    def _scale_features(self, X):\n",
        "        # Distinguish continuous from categorical features\n",
        "        all_categorical = set(self.dummy_columns) | set(self.ordinal_mappings.keys())\n",
        "        numeric_cols = [c for c in X.columns if np.issubdtype(X[c].dtype, np.number)]\n",
        "        continuous_feats = [c for c in numeric_cols if c not in all_categorical and c != 'const']\n",
        "\n",
        "        X_scaled=X.copy()\n",
        "        scaler_params_={}\n",
        "        if self.scale and continuous_feats:\n",
        "            if self.scaling_method=='standardization':\n",
        "                scaler_params_['mean']=X_scaled[continuous_feats].mean()\n",
        "                scaler_params_['std']=X_scaled[continuous_feats].std().replace(0,1)\n",
        "                X_scaled[continuous_feats]=(X_scaled[continuous_feats]-scaler_params_['mean'])/scaler_params_['std']\n",
        "            elif self.scaling_method=='minmax':\n",
        "                scaler_params_['min']=X_scaled[continuous_feats].min()\n",
        "                scaler_params_['max']=X_scaled[continuous_feats].max()\n",
        "                denom=(scaler_params_['max']-scaler_params_['min']).replace(0,1)\n",
        "                X_scaled[continuous_feats]=(X_scaled[continuous_feats]-scaler_params_['min'])/denom\n",
        "        else:\n",
        "            # No scaling or no continuous feats\n",
        "            scaler_params_['mean']=pd.Series([],dtype=float)\n",
        "            scaler_params_['std']=pd.Series([],dtype=float)\n",
        "\n",
        "        self.scaler_params_=scaler_params_\n",
        "        self.scaler_features_=continuous_feats\n",
        "        return X_scaled,scaler_params_\n",
        "\n",
        "    def _apply_scaling(self,X):\n",
        "        continuous_feats = self.scaler_features_\n",
        "        X_scaled=X.copy()\n",
        "        if self.scale and continuous_feats:\n",
        "            if self.scaling_method=='standardization':\n",
        "                X_scaled[continuous_feats]=(X_scaled[continuous_feats]-self.scaler_params_['mean'])/self.scaler_params_['std']\n",
        "            elif self.scaling_method=='minmax':\n",
        "                denom=(self.scaler_params_['max']-self.scaler_params_['min']).replace(0,1)\n",
        "                X_scaled[continuous_feats]=(X_scaled[continuous_feats]-self.scaler_params_['min'])/denom\n",
        "        return X_scaled\n",
        "\n",
        "    def _encode_new_data(self, X):\n",
        "        X_encoded=X.copy()\n",
        "        for f in self.categorical_features:\n",
        "            etype=self.categorical_encoding[f]\n",
        "            if etype=='nominal':\n",
        "                dummies=pd.get_dummies(X_encoded[f],prefix=f,drop_first=True)\n",
        "                missing_cols=set(self.dummy_columns)-set(dummies.columns)\n",
        "                for c in missing_cols:\n",
        "                    dummies[c]=0\n",
        "                dummies=dummies.reindex(columns=self.dummy_columns,fill_value=0)\n",
        "                X_encoded=pd.concat([X_encoded,dummies],axis=1)\n",
        "                X_encoded.drop(columns=[f],inplace=True)\n",
        "            elif etype=='ordinal':\n",
        "                mapping=self.ordinal_mappings.get(f)\n",
        "                if mapping is None:\n",
        "                    raise ValueError(f\"No mapping for {f}\")\n",
        "                X_encoded[f]=X_encoded[f].map(mapping)\n",
        "                if X_encoded[f].isnull().any():\n",
        "                    raise ValueError(\"Unseen category in ordinal feature.\")\n",
        "\n",
        "        if X_encoded.columns.duplicated().any():\n",
        "            X_encoded=X_encoded.loc[:,~X_encoded.columns.duplicated()]\n",
        "\n",
        "        return X_encoded\n",
        "\n",
        "    def predict_mu(self, X):\n",
        "        if self.encode_categorical:\n",
        "            if not isinstance(X, pd.DataFrame):\n",
        "                raise ValueError(\"X must be DataFrame for categorical.\")\n",
        "            X_encoded = self._encode_new_data(X)\n",
        "        else:\n",
        "            if isinstance(X, pd.DataFrame):\n",
        "                X_encoded = X.copy()\n",
        "            elif isinstance(X, np.ndarray):\n",
        "                X_encoded = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(X.shape[1])])\n",
        "            else:\n",
        "                raise ValueError(\"X must be a DataFrame or ndarray.\")\n",
        "\n",
        "        X_scaled = self._apply_scaling(X_encoded)\n",
        "\n",
        "        for col in X_scaled.columns:\n",
        "            if not np.issubdtype(X_scaled[col].dtype, np.number):\n",
        "                X_scaled[col] = pd.to_numeric(X_scaled[col], errors='coerce').fillna(0.0)\n",
        "\n",
        "        if 'const' not in self.feature_names_:\n",
        "            X_scaled = sm.add_constant(X_scaled)\n",
        "        X_scaled = X_scaled.reindex(columns=self.feature_names_, fill_value=0)\n",
        "\n",
        "        # Final cast to ensure floats\n",
        "        X_scaled = X_scaled.astype(float)\n",
        "\n",
        "        eta = X_scaled.values @ self.beta_\n",
        "        if self.family == 'gamma' and self.inv_link_func == self.inverse_link_gamma_inv:\n",
        "            eta = np.clip(eta, 1e-10, None)\n",
        "        mu = self.inv_link_func(eta)\n",
        "        return mu\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        mu=self.predict_mu(X)\n",
        "        if self.family=='linear':\n",
        "            return mu\n",
        "        elif self.family=='logistic':\n",
        "            return (mu>=threshold).astype(int)\n",
        "        elif self.family in ['poisson','negative_binomial']:\n",
        "            return np.round(mu).astype(int)\n",
        "        elif self.family=='gamma':\n",
        "            return mu\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported family {self.family}.\")\n",
        "\n",
        "    def coordinate_descent(self, beta_initial, X, W, z, reg_lambda, reg_alpha):\n",
        "        beta=beta_initial.copy()\n",
        "        n_features=X.shape[1]\n",
        "\n",
        "        if 'const' in self.feature_names_:\n",
        "            idx_const=self.feature_names_.index('const')\n",
        "        else:\n",
        "            idx_const=None\n",
        "\n",
        "        lambda_l1=reg_lambda*reg_alpha if self.regularization=='elasticnet' else reg_lambda\n",
        "\n",
        "        for iteration in range(self.max_cd_iter):\n",
        "            beta_old=beta.copy()\n",
        "            for j in range(n_features):\n",
        "                X_j=X[:,j]\n",
        "                r_j=z-(X@beta)+beta[j]*X_j\n",
        "                rho_j=(X_j*W*r_j).sum()\n",
        "                denom=(X_j**2*W).sum()\n",
        "                denom=max(denom,1e-8)\n",
        "\n",
        "                if j==idx_const:\n",
        "                    beta_j=rho_j/denom\n",
        "                else:\n",
        "                    if rho_j>lambda_l1:\n",
        "                        beta_j=(rho_j-lambda_l1)/denom\n",
        "                    elif rho_j<-lambda_l1:\n",
        "                        beta_j=(rho_j+lambda_l1)/denom\n",
        "                    else:\n",
        "                        beta_j=0.0\n",
        "                beta[j]=beta_j\n",
        "            delta=np.linalg.norm(beta-beta_old)\n",
        "            if self.verbose:\n",
        "                print(f\"    CD iter {iteration+1}: ||Δβ||={delta:.6e}\")\n",
        "            if delta<self.cd_tol:\n",
        "                if self.verbose:\n",
        "                    print(\"    CD converged.\")\n",
        "                break\n",
        "        return beta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Demos"
      ],
      "metadata": {
        "id": "aRLjgNVRoNar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def generate_linear_data(n_samples=500, n_features=3, noise=1.0, random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    X = pd.DataFrame(\n",
        "        np.random.randn(n_samples, n_features),\n",
        "        columns=[f'Feature_{i+1}' for i in range(n_features)]\n",
        "    )\n",
        "    true_beta = np.array([3.5, -2.0, 1.0])\n",
        "    intercept = 10.0\n",
        "    y = intercept + X.values @ true_beta + np.random.randn(n_samples)*noise\n",
        "    return X, y\n",
        "\n",
        "def generate_logistic_data(n_samples=500, random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    X = pd.DataFrame({\n",
        "        'Gender': np.random.choice(['Male','Female'], size=n_samples),\n",
        "        'Department': np.random.choice(['Sales','Engineering','HR'], size=n_samples),\n",
        "        'Experience': np.random.randint(1,21,size=n_samples),\n",
        "        'Education': np.random.choice(['High School','Bachelor','Master','PhD'], size=n_samples)\n",
        "    })\n",
        "\n",
        "    true_beta = {\n",
        "        'const': -1.0,\n",
        "        'Gender_Male': 0.5,\n",
        "        'Department_Engineering': 1.0,\n",
        "        'Department_HR':0.75,\n",
        "        'Education_Bachelor':0.2,\n",
        "        'Education_Master':0.4,\n",
        "        'Education_PhD':0.6,\n",
        "        'Experience':0.1\n",
        "    }\n",
        "\n",
        "    X_encoded=pd.get_dummies(X,drop_first=True)\n",
        "    for col in ['Gender_Male','Department_Engineering','Department_HR','Education_Bachelor','Education_Master','Education_PhD']:\n",
        "        if col not in X_encoded.columns:\n",
        "            X_encoded[col]=0\n",
        "    eta = (true_beta['const']\n",
        "           + true_beta['Gender_Male']*X_encoded['Gender_Male']\n",
        "           + true_beta['Department_Engineering']*X_encoded['Department_Engineering']\n",
        "           + true_beta['Department_HR']*X_encoded['Department_HR']\n",
        "           + true_beta['Education_Bachelor']*X_encoded['Education_Bachelor']\n",
        "           + true_beta['Education_Master']*X_encoded['Education_Master']\n",
        "           + true_beta['Education_PhD']*X_encoded['Education_PhD']\n",
        "           + true_beta['Experience']*X['Experience'])\n",
        "\n",
        "    p=1/(1+np.exp(-eta))\n",
        "    y=np.random.binomial(1,p)\n",
        "    return X,y\n",
        "\n",
        "def generate_poisson_data(n_samples=500,n_features=3,random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    X=pd.DataFrame(\n",
        "        np.random.randn(n_samples,n_features),\n",
        "        columns=[f'Feature_{i+1}' for i in range(n_features)]\n",
        "    )\n",
        "    true_beta=np.array([0.8,-1.2,0.5])\n",
        "    intercept=1.5\n",
        "    eta=intercept+X.values@true_beta\n",
        "    mu=np.exp(eta)\n",
        "    y=np.random.poisson(mu)\n",
        "    return X,y\n",
        "\n",
        "def generate_negative_binomial_data(n_samples=500,n_features=3,alpha=1.5,random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    X=pd.DataFrame(\n",
        "        np.random.randn(n_samples,n_features),\n",
        "        columns=[f'Feature_{i+1}' for i in range(n_features)]\n",
        "    )\n",
        "    true_beta=np.array([0.5,-1.0,0.3])\n",
        "    intercept=1.0\n",
        "    eta=intercept+X.values@true_beta\n",
        "    mu=np.exp(eta)\n",
        "    n=1/alpha\n",
        "    p=n/(n+mu)\n",
        "    y=np.random.negative_binomial(n,p)\n",
        "    return X,y\n",
        "\n",
        "def generate_gamma_data(n_samples=500,n_features=3,random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    X=pd.DataFrame({\n",
        "        'Age':np.random.randint(20,60,size=n_samples),\n",
        "        'Income':np.random.normal(50000,15000,size=n_samples),\n",
        "        'Debt':np.random.normal(15000,5000,size=n_samples)\n",
        "    })\n",
        "    eta=0.02*X['Age']+0.0001*X['Income']+0.0003*X['Debt']\n",
        "    mu=1/eta\n",
        "    alpha=2.0\n",
        "    y=np.random.gamma(shape=alpha,scale=mu/alpha)\n",
        "    return X,y\n",
        "\n",
        "def compare_coefficients(irls_coeffs, sm_coeffs, model_type):\n",
        "    comparison_df=pd.DataFrame({\n",
        "        'IRLSRegression': irls_coeffs,\n",
        "        'StatsModels': sm_coeffs\n",
        "    })\n",
        "    print(f\"\\n--- {model_type} Regression Coefficients Comparison ---\")\n",
        "    print(comparison_df)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def linear_regression_workflow():\n",
        "    print(\"=== Linear Regression ===\")\n",
        "    X,y=generate_linear_data()\n",
        "    irls=IRLSRegression(family='linear',link='identity',regularization='none',scale=False,encode_categorical=False,verbose=False)\n",
        "    irls.fit(X,y)\n",
        "    X_sm=sm.add_constant(X)\n",
        "    ols=sm.OLS(y,X_sm).fit()\n",
        "    irls_coeffs=pd.Series(irls.beta_,index=irls.feature_names_)\n",
        "    sm_coeffs=ols.params\n",
        "    compare_coefficients(irls_coeffs, sm_coeffs, \"Linear\")\n",
        "\n",
        "def logistic_regression_workflow():\n",
        "    print(\"=== Logistic Regression ===\")\n",
        "    X,y=generate_logistic_data()\n",
        "    categorical_encoding={\n",
        "        'Gender':'nominal',\n",
        "        'Department':'nominal',\n",
        "        'Education':'nominal'\n",
        "    }\n",
        "    irls=IRLSRegression(\n",
        "        family='logistic',\n",
        "        link='logit',\n",
        "        regularization='elasticnet',\n",
        "        reg_lambda=0.1,\n",
        "        reg_alpha=0.7,\n",
        "        l1_method='coordinate_descent',\n",
        "        scale=False,\n",
        "        encode_categorical=True,\n",
        "        categorical_features=['Gender','Department','Education'],\n",
        "        categorical_encoding=categorical_encoding,\n",
        "        verbose=False\n",
        "    )\n",
        "    irls.fit(X,y)\n",
        "    X_sm=pd.get_dummies(X,drop_first=True)\n",
        "    X_sm=sm.add_constant(X_sm)\n",
        "    X_sm=X_sm.astype(float)\n",
        "    y=y.astype(float)\n",
        "    logit=sm.Logit(y,X_sm).fit(disp=0)\n",
        "    irls_coeffs=pd.Series(irls.beta_,index=irls.feature_names_)\n",
        "    sm_coeffs=logit.params\n",
        "    compare_coefficients(irls_coeffs, sm_coeffs, \"Logistic (ElasticNet IRLS vs Unregularized SM)\")\n",
        "\n",
        "def poisson_regression_workflow():\n",
        "    print(\"=== Poisson Regression ===\")\n",
        "    X,y=generate_poisson_data()\n",
        "    irls=IRLSRegression(\n",
        "        family='poisson',\n",
        "        link='log',\n",
        "        regularization='none',\n",
        "        scale=False,\n",
        "        encode_categorical=False,\n",
        "        verbose=False\n",
        "    )\n",
        "    irls.fit(X,y)\n",
        "    X_sm=sm.add_constant(X)\n",
        "    poi=sm.GLM(y,X_sm,family=sm.families.Poisson()).fit()\n",
        "    irls_coeffs=pd.Series(irls.beta_,index=irls.feature_names_)\n",
        "    sm_coeffs=poi.params\n",
        "    compare_coefficients(irls_coeffs, sm_coeffs, \"Poisson\")\n",
        "\n",
        "def negative_binomial_regression_workflow():\n",
        "    print(\"=== Negative Binomial Regression ===\")\n",
        "    X,y=generate_negative_binomial_data()\n",
        "    irls=IRLSRegression(\n",
        "        family='negative_binomial',\n",
        "        link='log',\n",
        "        regularization='none',\n",
        "        scale=False,\n",
        "        encode_categorical=False,\n",
        "        verbose=False\n",
        "    )\n",
        "    irls.fit(X,y)\n",
        "    X_sm=sm.add_constant(X)\n",
        "    # Using alpha=1.5 as in data generation\n",
        "    nb=sm.GLM(y,X_sm,family=sm.families.NegativeBinomial(alpha=1.5)).fit()\n",
        "    irls_coeffs=pd.Series(irls.beta_,index=irls.feature_names_)\n",
        "    sm_coeffs=nb.params\n",
        "    compare_coefficients(irls_coeffs, sm_coeffs, \"Negative Binomial\")\n",
        "\n",
        "def gamma_regression_workflow():\n",
        "    print(\"=== Gamma Regression ===\")\n",
        "    X,y=generate_gamma_data()\n",
        "    irls=IRLSRegression(\n",
        "        family='gamma',\n",
        "        link='inverse',\n",
        "        regularization='none',\n",
        "        scale=False,\n",
        "        encode_categorical=False,\n",
        "        verbose=False\n",
        "    )\n",
        "    irls.fit(X,y)\n",
        "    X_sm=sm.add_constant(X)\n",
        "    gamma_mod=sm.GLM(y,X_sm,family=sm.families.Gamma(link=sm.families.links.inverse_power())).fit()\n",
        "    irls_coeffs=pd.Series(irls.beta_,index=irls.feature_names_)\n",
        "    sm_coeffs=gamma_mod.params\n",
        "    compare_coefficients(irls_coeffs, sm_coeffs, \"Gamma\")\n",
        "\n",
        "def main():\n",
        "    linear_regression_workflow()\n",
        "    logistic_regression_workflow()\n",
        "    poisson_regression_workflow()\n",
        "    negative_binomial_regression_workflow()\n",
        "    gamma_regression_workflow()\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUkFazuTmnYs",
        "outputId": "6751fa62-b3c1-4bc1-fbed-29a085809c7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Linear Regression ===\n",
            "\n",
            "--- Linear Regression Coefficients Comparison ---\n",
            "           IRLSRegression  StatsModels\n",
            "const           10.037212    10.037212\n",
            "Feature_1        3.478160     3.478160\n",
            "Feature_2       -2.054121    -2.054121\n",
            "Feature_3        0.949873     0.949873\n",
            "\n",
            "\n",
            "=== Logistic Regression ===\n",
            "\n",
            "--- Logistic (ElasticNet IRLS vs Unregularized SM) Regression Coefficients Comparison ---\n",
            "                       IRLSRegression  StatsModels\n",
            "const                       -0.621151    -0.626555\n",
            "Experience                   0.146704     0.146833\n",
            "Gender_Male                  0.031268     0.034275\n",
            "Department_HR                0.799800     0.803787\n",
            "Department_Sales            -0.550585    -0.553149\n",
            "Education_High School       -0.369739    -0.369628\n",
            "Education_Master             0.319290     0.326127\n",
            "Education_PhD                0.461118     0.468041\n",
            "\n",
            "\n",
            "=== Poisson Regression ===\n",
            "\n",
            "--- Poisson Regression Coefficients Comparison ---\n",
            "           IRLSRegression  StatsModels\n",
            "const            1.460261     1.460261\n",
            "Feature_1        0.801814     0.801814\n",
            "Feature_2       -1.223365    -1.223365\n",
            "Feature_3        0.508318     0.508318\n",
            "\n",
            "\n",
            "=== Negative Binomial Regression ===\n",
            "\n",
            "--- Negative Binomial Regression Coefficients Comparison ---\n",
            "           IRLSRegression  StatsModels\n",
            "const           -3.656764     0.933772\n",
            "Feature_1        2.399338     0.544801\n",
            "Feature_2       -3.771848    -0.973158\n",
            "Feature_3        1.479404     0.311326\n",
            "\n",
            "\n",
            "=== Gamma Regression ===\n",
            "\n",
            "--- Gamma Regression Coefficients Comparison ---\n",
            "        IRLSRegression  StatsModels\n",
            "const    -1.000000e-10    -1.296002\n",
            "Age      -1.103188e-24     0.006564\n",
            "Income   -1.587907e-26     0.000123\n",
            "Debt     -4.399600e-26     0.000356\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inconsistencies still present in the negative binomial and gamma regression tasks. Must study IRLS when dispersion parameter is present."
      ],
      "metadata": {
        "id": "qFJ3nhx91POF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Demos"
      ],
      "metadata": {
        "id": "KDN6JBVRoQXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def generate_categorical_data(n_samples=100, random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    data = {\n",
        "        'Gender': np.random.choice(['Male', 'Female'], size=n_samples),\n",
        "        'Department': np.random.choice(['Sales', 'Engineering', 'HR', 'Marketing'], size=n_samples),\n",
        "        'Education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], size=n_samples),\n",
        "        'Experience': np.random.randint(1, 21, size=n_samples),\n",
        "        'Salary': np.random.normal(60000, 15000, size=n_samples)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "def display_encoding_details(model, model_type):\n",
        "    print(f\"\\n--- {model_type} Regression Encoding Details ---\")\n",
        "    if model.encode_categorical:\n",
        "        print(\"Dummy Variables Created (Nominal Features):\")\n",
        "        print(model.dummy_columns)\n",
        "        print(\"\\nOrdinal Mappings:\")\n",
        "        for feature, mapping in model.ordinal_mappings.items():\n",
        "            print(f\"  {feature}: {mapping}\")\n",
        "    else:\n",
        "        print(\"No categorical encoding was applied.\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "def encoding_workflow():\n",
        "    print(\"=== Encoding Capabilities Demonstration ===\")\n",
        "    df = generate_categorical_data(n_samples=200)\n",
        "    print(\"Sample of the Original Dataset:\")\n",
        "    print(df.head())\n",
        "\n",
        "    X = df[['Gender', 'Department', 'Education', 'Experience']]\n",
        "    y = df['Salary']\n",
        "\n",
        "    categorical_encoding = {\n",
        "        'Gender': 'nominal',\n",
        "        'Department': 'nominal',\n",
        "        'Education': 'ordinal'\n",
        "    }\n",
        "    ordinal_mapping = {\n",
        "        'Education': ['High School', 'Bachelor', 'Master', 'PhD']\n",
        "    }\n",
        "\n",
        "    irls_model = IRLSRegression(\n",
        "        family='linear',\n",
        "        link='identity',\n",
        "        regularization='none',\n",
        "        scale=True,\n",
        "        scaling_method='standardization',\n",
        "        encode_categorical=True,\n",
        "        categorical_features=['Gender', 'Department', 'Education'],\n",
        "        categorical_encoding=categorical_encoding,\n",
        "        ordinal_mapping=ordinal_mapping,\n",
        "        verbose=True\n",
        "    )\n",
        "    irls_model.fit(X, y)\n",
        "\n",
        "    print(\"\\nTransformed Feature Names After Encoding and Scaling:\")\n",
        "    print(irls_model.feature_names_)\n",
        "    display_encoding_details(irls_model, \"Linear\")\n",
        "\n",
        "    # Manual replication of IRLS process\n",
        "    X_encoded = X.copy()\n",
        "\n",
        "    # Nominal encoding\n",
        "    for feature in ['Gender', 'Department']:\n",
        "        dummies = pd.get_dummies(X_encoded[feature], prefix=feature, drop_first=True)\n",
        "        X_encoded = pd.concat([X_encoded, dummies], axis=1)\n",
        "        X_encoded.drop(columns=[feature], inplace=True)\n",
        "\n",
        "    # Ordinal encoding\n",
        "    edu_map = {cat: i for i, cat in enumerate(ordinal_mapping['Education'], start=1)}\n",
        "    X_encoded['Education'] = X_encoded['Education'].map(edu_map)\n",
        "\n",
        "    # Cast to float after encoding\n",
        "    X_encoded = X_encoded.astype(float)\n",
        "\n",
        "    # Now we have a DataFrame with numeric columns (Experience, Education) and dummies\n",
        "    scaler_mean = irls_model.scaler_params_.get('mean', pd.Series(dtype=float))\n",
        "    scaler_std = irls_model.scaler_params_.get('std', pd.Series(dtype=float))\n",
        "    scaler_features = irls_model.scaler_features_\n",
        "\n",
        "    X_scaled = X_encoded.copy()\n",
        "    if irls_model.scale and len(scaler_features) > 0:\n",
        "        for col in scaler_features:\n",
        "            X_scaled[col] = (X_scaled[col] - scaler_mean[col]) / scaler_std[col]\n",
        "\n",
        "    # Add const and reorder columns\n",
        "    X_scaled = sm.add_constant(X_scaled)\n",
        "    X_scaled = X_scaled.reindex(columns=irls_model.feature_names_, fill_value=0)\n",
        "\n",
        "    # Cast again to float to ensure all columns are float (no booleans)\n",
        "    X_scaled = X_scaled.astype(float)\n",
        "\n",
        "    print(\"\\nSample of the Encoded and Scaled Feature Set:\")\n",
        "    # Show more rows\n",
        "    with pd.option_context('display.max_rows', 20, 'display.max_columns', None):\n",
        "        display(X_scaled.head(20))\n",
        "\n",
        "    print(\"\\n--- Making Predictions on New Data ---\")\n",
        "    new_data = pd.DataFrame({\n",
        "        'Gender': ['Female', 'Male'],\n",
        "        'Department': ['Engineering', 'HR'],\n",
        "        'Education': ['Master', 'Bachelor'],\n",
        "        'Experience': [5, 15]\n",
        "    })\n",
        "    print(\"\\nNew Data for Prediction:\")\n",
        "    print(new_data)\n",
        "    predicted_salary = irls_model.predict_mu(new_data)\n",
        "    print(\"\\nPredicted Salary (Expected Mean) for New Data:\")\n",
        "    print(predicted_salary)\n",
        "\n",
        "    print(\"\\n--- Handling Unseen Categories During Prediction ---\")\n",
        "    new_data_unseen = pd.DataFrame({\n",
        "        'Gender': ['Female', 'Male'],\n",
        "        'Department': ['Finance', 'HR'],\n",
        "        'Education': ['Master', 'Bachelor'],\n",
        "        'Experience': [5, 15]\n",
        "    })\n",
        "    print(\"\\nNew Data with Unseen Category for 'Department':\")\n",
        "    print(new_data_unseen)\n",
        "    try:\n",
        "        predicted_salary_unseen = irls_model.predict_mu(new_data_unseen)\n",
        "        print(\"\\nPredicted Salary for New Data with Unseen Categories:\")\n",
        "        print(predicted_salary_unseen)\n",
        "    except ValueError as e:\n",
        "        print(f\"\\nError during prediction with unseen categories: {e}\")\n",
        "\n",
        "    print(\"\\n--- Making Predictions on Consistent New Data ---\")\n",
        "    new_data_consistent = pd.DataFrame({\n",
        "        'Gender': ['Female', 'Male'],\n",
        "        'Department': ['Engineering', 'HR'],\n",
        "        'Education': ['PhD', 'High School'],\n",
        "        'Experience': [10, 3]\n",
        "    })\n",
        "    print(\"\\nNew Consistent Data for Prediction:\")\n",
        "    print(new_data_consistent)\n",
        "    predicted_salary_consistent = irls_model.predict_mu(new_data_consistent)\n",
        "    print(\"\\nPredicted Salary for Consistent New Data:\")\n",
        "    print(predicted_salary_consistent)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    encoding_workflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "whlP1ijfmnVm",
        "outputId": "43cdb067-5254-4fc7-d8fc-e49c537b7386"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Encoding Capabilities Demonstration ===\n",
            "Sample of the Original Dataset:\n",
            "   Gender Department    Education  Experience        Salary\n",
            "0    Male         HR          PhD          13  80382.249500\n",
            "1  Female  Marketing          PhD          20  55704.802258\n",
            "2    Male         HR       Master          15  60684.117599\n",
            "3    Male      Sales  High School           3  65837.693642\n",
            "4    Male  Marketing          PhD           8  55988.990432\n",
            "    ||Δβ||=5.865498e+04\n",
            "    ||Δβ||=0.000000e+00\n",
            "Converged in 2 iterations.\n",
            "\n",
            "Transformed Feature Names After Encoding and Scaling:\n",
            "['const', 'Education', 'Experience', 'Gender_Male', 'Department_HR', 'Department_Marketing', 'Department_Sales']\n",
            "\n",
            "--- Linear Regression Encoding Details ---\n",
            "Dummy Variables Created (Nominal Features):\n",
            "['Gender_Male', 'Department_HR', 'Department_Marketing', 'Department_Sales']\n",
            "\n",
            "Ordinal Mappings:\n",
            "  Education: {'High School': 1, 'Bachelor': 2, 'Master': 3, 'PhD': 4}\n",
            "\n",
            "\n",
            "\n",
            "Sample of the Encoded and Scaled Feature Set:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    const  Education  Experience  Gender_Male  Department_HR  \\\n",
              "0     1.0        4.0    0.405622          1.0            1.0   \n",
              "1     1.0        4.0    1.591155          0.0            0.0   \n",
              "2     1.0        3.0    0.744346          1.0            1.0   \n",
              "3     1.0        1.0   -1.287998          1.0            0.0   \n",
              "4     1.0        4.0   -0.441188          1.0            0.0   \n",
              "5     1.0        4.0    1.591155          0.0            0.0   \n",
              "6     1.0        2.0    0.913708          1.0            0.0   \n",
              "7     1.0        4.0    0.405622          1.0            0.0   \n",
              "8     1.0        4.0    1.252432          1.0            0.0   \n",
              "9     1.0        2.0   -0.102464          0.0            0.0   \n",
              "10    1.0        3.0    1.421793          1.0            1.0   \n",
              "11    1.0        4.0    1.083070          1.0            1.0   \n",
              "12    1.0        2.0    1.421793          1.0            0.0   \n",
              "13    1.0        1.0   -0.949274          1.0            1.0   \n",
              "14    1.0        3.0   -0.271826          0.0            1.0   \n",
              "15    1.0        1.0    0.236260          1.0            0.0   \n",
              "16    1.0        1.0   -1.626721          0.0            0.0   \n",
              "17    1.0        2.0   -1.626721          0.0            0.0   \n",
              "18    1.0        4.0    0.744346          0.0            0.0   \n",
              "19    1.0        2.0   -1.457359          1.0            1.0   \n",
              "\n",
              "    Department_Marketing  Department_Sales  \n",
              "0                    0.0               0.0  \n",
              "1                    1.0               0.0  \n",
              "2                    0.0               0.0  \n",
              "3                    0.0               1.0  \n",
              "4                    1.0               0.0  \n",
              "5                    0.0               1.0  \n",
              "6                    1.0               0.0  \n",
              "7                    1.0               0.0  \n",
              "8                    0.0               0.0  \n",
              "9                    0.0               1.0  \n",
              "10                   0.0               0.0  \n",
              "11                   0.0               0.0  \n",
              "12                   0.0               1.0  \n",
              "13                   0.0               0.0  \n",
              "14                   0.0               0.0  \n",
              "15                   0.0               1.0  \n",
              "16                   1.0               0.0  \n",
              "17                   0.0               1.0  \n",
              "18                   1.0               0.0  \n",
              "19                   0.0               0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23353dab-3ef8-4631-9be6-02f05d8b7773\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>const</th>\n",
              "      <th>Education</th>\n",
              "      <th>Experience</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Department_HR</th>\n",
              "      <th>Department_Marketing</th>\n",
              "      <th>Department_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.405622</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.591155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.744346</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.287998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.441188</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.591155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.913708</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.405622</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.252432</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.102464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.421793</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.083070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.421793</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.949274</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.271826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.236260</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.626721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.626721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.744346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.457359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23353dab-3ef8-4631-9be6-02f05d8b7773')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23353dab-3ef8-4631-9be6-02f05d8b7773 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23353dab-3ef8-4631-9be6-02f05d8b7773');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-831a86a8-cfac-4088-a29a-b6f49f067c63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-831a86a8-cfac-4088-a29a-b6f49f067c63')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-831a86a8-cfac-4088-a29a-b6f49f067c63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    encoding_workflow()\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"const\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Education\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2085223687584246,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.114786464823486,\n        \"min\": -1.6267213846670507,\n        \"max\": 1.5911553783390882,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1.0830695736539082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender_Male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4893604849295929,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Department_HR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4893604849295929,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Department_Marketing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47016234598162715,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Department_Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47016234598162715,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Making Predictions on New Data ---\n",
            "\n",
            "New Data for Prediction:\n",
            "   Gender   Department Education  Experience\n",
            "0  Female  Engineering    Master           5\n",
            "1    Male           HR  Bachelor          15\n",
            "\n",
            "Predicted Salary (Expected Mean) for New Data:\n",
            "[-3326.2037955   2793.30054855]\n",
            "\n",
            "--- Handling Unseen Categories During Prediction ---\n",
            "\n",
            "New Data with Unseen Category for 'Department':\n",
            "   Gender Department Education  Experience\n",
            "0  Female    Finance    Master           5\n",
            "1    Male         HR  Bachelor          15\n",
            "\n",
            "Predicted Salary for New Data with Unseen Categories:\n",
            "[-3326.2037955   2793.30054855]\n",
            "\n",
            "--- Making Predictions on Consistent New Data ---\n",
            "\n",
            "New Consistent Data for Prediction:\n",
            "   Gender   Department    Education  Experience\n",
            "0  Female  Engineering          PhD          10\n",
            "1    Male           HR  High School           3\n",
            "\n",
            "Predicted Salary for Consistent New Data:\n",
            "[-2217.22042314  -575.91467958]\n"
          ]
        }
      ]
    }
  ]
}